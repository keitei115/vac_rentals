{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1620291128814,
     "user": {
      "displayName": "工藤奎太朗",
      "photoUrl": "",
      "userId": "17571128482548330974"
     },
     "user_tz": -540
    },
    "id": "TcrFhXk0GYV7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df = pd.DataFrame()\n",
    "test_X_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sitc_trainee_03\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:994: UserWarning: unknown class(es) ['Wide clearance to shower and toilet'] will be ignored\n",
      "  warnings.warn('unknown class(es) {0} will be ignored'\n",
      "C:\\Users\\sitc_trainee_03\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:994: UserWarning: unknown class(es) ['Wide clearance to shower and toilet'] will be ignored\n",
      "  warnings.warn('unknown class(es) {0} will be ignored'\n"
     ]
    }
   ],
   "source": [
    "# strで書かれてしまったリストをndarrayに変換する\n",
    "def str_to_nd(strs):\n",
    "    strs = re.sub('[{}\"]','',strs)\n",
    "    str_list = strs.split(',')\n",
    "    str_nd = np.array(str_list)\n",
    "    return str_nd\n",
    "\n",
    "# リストをOne-Hotに変換する\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "def list_to_onehot(train,test):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_onehot = mlb.fit_transform(train.values)\n",
    "    test_onehot = mlb.transform(test.values)\n",
    "    train_onehot_df = pd.DataFrame(train_onehot, columns = mlb.classes_)\n",
    "    columns_list = train_onehot_df.mean()[train_onehot_df.mean()>0.00].index.tolist()\n",
    "    train_onehot_df = train_onehot_df[columns_list]\n",
    "    test_onehot_df = pd.DataFrame(test_onehot, columns = mlb.classes_)\n",
    "    test_onehot_df = test_onehot_df[columns_list]\n",
    "    return train_onehot_df.astype('int').astype('category'),test_onehot_df.astype('int').astype('category')\n",
    "\n",
    "# アメニティデータ\n",
    "train['amenities'] = train['amenities'].map(str_to_nd)\n",
    "test['amenities'] = test['amenities'].map(str_to_nd)\n",
    "train_X_df = pd.concat([train_X_df,list_to_onehot(train['amenities'],test['amenities'])[0]], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,list_to_onehot(train['amenities'],test['amenities'])[1]], axis=1)\n",
    "# アメニティの数\n",
    "train_X_df = pd.concat([train_X_df,train['amenities'].map(lambda x:len(x)).rename('am_num')], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test['amenities'].map(lambda x:len(x)).rename('am_num')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリー系のデータをラベルにする\n",
    "import itertools\n",
    "import category_encoders as ce\n",
    "def df_to_label(train,test):\n",
    "    train,test = train.fillna('nan'),test.fillna('nan')\n",
    "    oe = ce.OrdinalEncoder(handle_unknown='return nan')\n",
    "    train_oe = oe.fit_transform(train).fillna(999).astype(int).astype('category') # 欠損値はありえない数値で埋める\n",
    "    test_oe = oe.transform(test).fillna(999).astype(int).astype('category')\n",
    "    return train_oe,test_oe\n",
    "\n",
    "# カテゴリー系データ\n",
    "cat_list = ['bed_type','cancellation_policy','city','cleaning_fee','host_has_profile_pic','host_identity_verified','instant_bookable','property_type','room_type','neighbourhood']\n",
    "train_X_df = pd.concat([train_X_df,df_to_label(train[cat_list],test[cat_list])[0]], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,df_to_label(train[cat_list],test[cat_list])[1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付関連のデータを整形\n",
    "import datetime\n",
    "def str_to_date(df):\n",
    "    # 年と月だけを抜き出す、nanはそのまま\n",
    "    df_year = df.applymap(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').year if x==x else x)\n",
    "    df_month = df.applymap(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month if x==x else x)\n",
    "\n",
    "    # 月で換算する(わかりやすくするために年は2000までは切り捨て)\n",
    "    df_date = (df_year - 2000) * 12 + df_month\n",
    "\n",
    "    return df_date\n",
    "\n",
    "# 日付関連のデータ\n",
    "date_list = ['host_since','first_review','last_review']\n",
    "train_X_df = pd.concat([train_X_df,str_to_date(train[date_list])], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,str_to_date(test[date_list])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 月データ(季節)\n",
    "str_to_month = lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month if x==x else x\n",
    "train_X_df = pd.concat([train_X_df,train['host_since'].map(str_to_month).rename('host_since_month')], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test['host_since'].map(str_to_month).rename('host_since_month')], axis=1)\n",
    "\n",
    "train_X_df = pd.concat([train_X_df,train['first_review'].map(str_to_month).rename('first_review_month')], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test['first_review'].map(str_to_month).rename('first_review_month')], axis=1)\n",
    "\n",
    "train_X_df = pd.concat([train_X_df,train['last_review'].map(str_to_month).rename('last_review_month')], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test['last_review'].map(str_to_month).rename('last_review_month')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反応があるかないかをOne-Hotデータで表現する\n",
    "def res_to_onehot(df):\n",
    "    df = df.applymap(lambda x: 1 if x==x else 0)\n",
    "    df = df.set_axis([x+'_hot' for x in df.columns], axis=1)\n",
    "    return df.astype('category')\n",
    "\n",
    "#res_list = ['first_review','host_since','last_review','thumbnail_url']\n",
    "res_list = ['host_since']\n",
    "train_X_df = pd.concat([train_X_df,res_to_onehot(train[res_list])], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,res_to_onehot(test[res_list])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str型のパーセンテージで書かれたデータを0~1のfloat型にする\n",
    "def strper_to_float(strper):\n",
    "    if strper==strper:\n",
    "        strnum = re.sub('%','',strper)\n",
    "        num_float = float(strnum) / 100.\n",
    "    else:\n",
    "        num_float = np.nan\n",
    "    return num_float\n",
    "\n",
    "# str型のパーセンテージ\n",
    "train['host_response_rate'] = train['host_response_rate'].map(strper_to_float)\n",
    "test['host_response_rate'] = test['host_response_rate'].map(strper_to_float)\n",
    "\n",
    "# float型データ\n",
    "num_list = ['accommodates','bathrooms','bedrooms','beds','latitude','longitude','number_of_reviews','review_scores_rating','host_response_rate']\n",
    "train_X_df = pd.concat([train_X_df,train[num_list]], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test[num_list]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 緯度経度から地理情報を入手\n",
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine()\n",
    "def latlon_to_geo(lat, lon):\n",
    "    d = search.by_coordinates(lat, lon, radius=20)[0].to_dict()\n",
    "    return pd.DataFrame([d])\n",
    "\n",
    "def data_to_geo(df):\n",
    "    geo = pd.concat([latlon_to_geo(x,y) for x,y in zip(df['latitude'],df['longitude'])])\n",
    "    return geo\n",
    "\n",
    "def geo_cat_num(geo):\n",
    "    geo['zipcode'] = geo['zipcode'].apply(lambda x:str(x)[:5])\n",
    "    cat_list = ['zipcode', \n",
    "                'major_city']\n",
    "\n",
    "    num_list = ['population', \n",
    "                'population_density', \n",
    "                'land_area_in_sqmi', \n",
    "                'water_area_in_sqmi', \n",
    "                'housing_units', \n",
    "                'occupied_housing_units', \n",
    "                'median_home_value', \n",
    "                'median_household_income']\n",
    "    \n",
    "    return geo[cat_list], geo[num_list]\n",
    "\n",
    "# DataFrameの作成が非常に遅いため、DataFrameを作成したらcsvとして保存し次に使うときはcsvから読み込む\n",
    "\n",
    "if os.path.isfile('train_geo.csv'):\n",
    "    train_geo = pd.read_csv('train_geo.csv', index_col=0)\n",
    "else:\n",
    "    train_geo = data_to_geo(train).reset_index()\n",
    "    train_geo.to_csv('train_geo.csv', header=True, index=True)\n",
    "train_geo_cat, train_geo_num = geo_cat_num(train_geo)\n",
    "\n",
    "if os.path.isfile('test_geo.csv'):\n",
    "    test_geo = pd.read_csv('test_geo.csv', index_col=0)\n",
    "else:\n",
    "    test_geo = data_to_geo(test).reset_index()\n",
    "    test_geo.to_csv('test_geo.csv', header=True, index=True)\n",
    "test_geo_cat, test_geo_num = geo_cat_num(test_geo)\n",
    "\n",
    "train_X_df = pd.concat([train_X_df,df_to_label(train_geo_cat,test_geo_cat)[0]], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,df_to_label(train_geo_cat,test_geo_cat)[1]], axis=1)\n",
    "train_X_df = pd.concat([train_X_df,train_geo_num], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test_geo_num], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptionの単語数を調べる\n",
    "from collections import Counter\n",
    "wordnum = lambda x:sum(Counter(x.split()).values())\n",
    "train_X_df = pd.concat([train_X_df,train['description'].map(wordnum).rename('word_num')], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test['description'].map(wordnum).rename('word_num')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 部屋数\n",
    "train_X_df['rooms'] = train_X_df['bedrooms'] + train_X_df['bathrooms']\n",
    "test_X_df['rooms'] = test_X_df['bedrooms'] + test_X_df['bathrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 価格が高い地点との距離を測る\n",
    "top_loc = np.array([[-118.813009,34.028313],[-118.448221,34.132164]])\n",
    "\n",
    "def u_dis(x1,y1,x2,y2):\n",
    "    return np.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "\n",
    "def min_dis(df):\n",
    "    tmp = np.empty(2)\n",
    "    for i,x,y in zip(range(1),top_loc[:,0],top_loc[:,1]):\n",
    "        tmp[i] = u_dis(df['longitude'],df['latitude'],x,y)\n",
    "    return tmp\n",
    "\n",
    "train_X_df = pd.concat([train_X_df,train_X_df.apply(min_dis, axis=1).apply(pd.Series)], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test_X_df.apply(min_dis, axis=1).apply(pd.Series)], axis=1)\n",
    "\n",
    "train_X_df = train_X_df.rename(columns=dict([(x,'dis_'+str(x)) for x in range(2)]))\n",
    "test_X_df = test_X_df.rename(columns=dict([(x,'dis_'+str(x)) for x in range(2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 占有住宅率\n",
    "train_X_df['occupied_housing_rate'] = train_X_df['occupied_housing_units'] / train_X_df['housing_units']\n",
    "test_X_df['occupied_housing_rate'] = test_X_df['occupied_housing_units'] / test_X_df['housing_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用データの作成\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "remnum = lambda x:re.sub(r'[0-9]+', \" \", x)\n",
    "remstr = lambda x:re.sub(r'[\\．_－―─\\-‐|\\“■×+α÷⇒—●□(=)*&^%$#@!~`){}…\\[\\]\\\"\\'\\”\\’:;<>?・,\\./→←○\\n\\u3000]+', \" \", x)\n",
    "shape_sent = lambda x:word_tokenize(x.lower())\n",
    "\n",
    "train_desc = train['description'].map(remnum).map(remstr).map(shape_sent)\n",
    "test_desc = test['description'].map(remnum).map(remstr).map(shape_sent)\n",
    "\n",
    "train_name = train['name'].map(remnum).map(remstr).map(shape_sent)\n",
    "test_name = test['name'].map(remnum).map(remstr).map(shape_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sitc_trainee_03\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# description用モデルの作成\n",
    "vector_size=50\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "if os.path.isfile('description.model'):\n",
    "    model_desc = Word2Vec.load('description.model')\n",
    "else:\n",
    "    # word2vecのモデル作成\n",
    "    sentence = train_desc.values.tolist()\n",
    "    model_desc = Word2Vec(sentence,vector_size=vector_size,window=15,min_count=5)\n",
    "    model_desc.train(sentence,total_examples=len(sentence),epochs=100)\n",
    "    model_desc.save('description.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name用モデルの作成\n",
    "vector_size_name=50\n",
    "if os.path.isfile('name.model'):\n",
    "    model_name = Word2Vec.load('name.model')\n",
    "else:\n",
    "    # word2vecのモデル作成\n",
    "    sentence = train_name.values.tolist()\n",
    "    model_name = Word2Vec(sentence,vector_size=vector_size,window=10,min_count=5)\n",
    "    model_name.train(sentence,total_examples=len(sentence),epochs=50)\n",
    "    model_name.save('name.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptionの文章ベクトルの作成\n",
    "def wordvec2docvec(sentence):\n",
    "    # 文章ベクトルの初期値（0ベクトルを初期値とする）\n",
    "    docvecs = np.zeros(vector_size, dtype=\"float32\")\n",
    "\n",
    "    # 文章の中に存在する単語の数\n",
    "    denomenator = len(sentence)\n",
    "    # 文章内の各単語ベクトルを足し合わせる\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            temp = model_desc.wv[word]\n",
    "        except:\n",
    "            denomenator -= 1\n",
    "            continue\n",
    "        docvecs += temp\n",
    "\n",
    "    # 文章に現れる単語のうち、モデルに存在した単語の数で割る\n",
    "    if denomenator > 0:\n",
    "        docvecs =  docvecs / denomenator\n",
    "\n",
    "    return docvecs\n",
    "\n",
    "train_X_df = pd.concat([train_X_df,train_desc.map(wordvec2docvec).apply(pd.Series)], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test_desc.map(wordvec2docvec).apply(pd.Series)], axis=1)\n",
    "train_X_df = train_X_df.rename(columns=dict([(x,'desc_'+str(x)) for x in range(vector_size)]))\n",
    "test_X_df = test_X_df.rename(columns=dict([(x,'desc_'+str(x)) for x in range(vector_size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4bd9d5d85c3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mtrain_X_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_X_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordvec2docvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtest_X_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_X_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordvec2docvec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mtrain_X_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_X_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'name_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mtest_X_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'name_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    304\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdefault_index\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m   5649\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRangeIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5651\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mRangeIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, start, stop, step, dtype, copy, name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_extract_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# RangeIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# nameの文章ベクトルの作成\n",
    "def wordvec2docvec(sentence):\n",
    "    # 文章ベクトルの初期値（0ベクトルを初期値とする）\n",
    "    docvecs = np.zeros(vector_size_name, dtype=\"float32\")\n",
    "\n",
    "    # 文章の中に存在する単語の数\n",
    "    denomenator = len(sentence)\n",
    "    # 文章内の各単語ベクトルを足し合わせる\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            temp = model_name.wv[word]\n",
    "        except:\n",
    "            denomenator -= 1\n",
    "            continue\n",
    "        docvecs += temp\n",
    "\n",
    "    # 文章に現れる単語のうち、モデルに存在した単語の数で割る\n",
    "    if denomenator > 0:\n",
    "        docvecs =  docvecs / denomenator\n",
    "\n",
    "    return docvecs\n",
    "\n",
    "train_X_df = pd.concat([train_X_df,train_name.map(wordvec2docvec).apply(pd.Series)], axis=1)\n",
    "test_X_df = pd.concat([test_X_df,test_name.map(wordvec2docvec).apply(pd.Series)], axis=1)\n",
    "train_X_df = train_X_df.rename(columns=dict([(x,'name_'+str(x)) for x in range(vector_size)]))\n",
    "test_X_df = test_X_df.rename(columns=dict([(x,'name_'+str(x)) for x in range(vector_size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  24-hour check-in Air conditioning Bathtub Bed linens Breakfast  \\\n0                0                0       0          0         0   \n1                1                1       0          0         0   \n2                1                0       1          0         0   \n3                0                1       0          0         0   \n4                0                1       0          0         0   \n5                0                1       0          0         0   \n6                1                0       0          0         0   \n7                0                1       0          0         0   \n8                0                1       0          0         0   \n9                0                1       0          0         0   \n\n  Buzzer/wireless intercom Cable TV Carbon monoxide detector Cat(s)  \\\n0                        0        0                        0      0   \n1                        0        1                        1      0   \n2                        1        0                        1      0   \n3                        1        1                        1      0   \n4                        1        0                        1      0   \n5                        0        0                        0      0   \n6                        0        0                        1      1   \n7                        0        1                        0      0   \n8                        0        0                        1      0   \n9                        0        0                        0      0   \n\n  Children’s books and toys Coffee maker Cooking basics Dishes and silverware  \\\n0                         0            0              0                     0   \n1                         0            0              0                     0   \n2                         0            0              0                     0   \n3                         0            0              0                     0   \n4                         0            0              0                     0   \n5                         0            0              0                     0   \n6                         0            0              0                     0   \n7                         0            0              0                     0   \n8                         0            0              0                     0   \n9                         0            0              0                     0   \n\n  Dishwasher Dog(s) Doorman Dryer Elevator Elevator in building Essentials  \\\n0          0      0       0     1        0                    0          0   \n1          0      0       0     1        0                    0          1   \n2          0      0       0     1        0                    0          1   \n3          0      0       0     1        0                    0          1   \n4          0      0       0     1        1                    0          1   \n5          0      0       0     0        0                    0          1   \n6          0      0       0     0        0                    0          1   \n7          0      0       0     1        0                    1          0   \n8          0      0       0     0        0                    0          1   \n9          0      0       0     0        0                    0          0   \n\n  Extra pillows and blankets Family/kid friendly Fire extinguisher  \\\n0                          0                   0                 0   \n1                          0                   0                 0   \n2                          0                   0                 1   \n3                          0                   0                 0   \n4                          0                   0                 1   \n5                          0                   0                 0   \n6                          0                   1                 1   \n7                          0                   1                 0   \n8                          0                   0                 1   \n9                          0                   0                 0   \n\n  First aid kit Free parking on premises Garden or backyard Gym Hair dryer  \\\n0             0                        1                  0   0          0   \n1             1                        1                  0   0          0   \n2             1                        0                  0   0          1   \n3             1                        0                  0   0          0   \n4             0                        0                  0   0          1   \n5             0                        0                  0   0          1   \n6             1                        1                  0   0          1   \n7             0                        1                  0   1          0   \n8             0                        0                  0   0          0   \n9             0                        0                  0   0          0   \n\n  Hangers Heating Host greets you Hot tub Hot water Indoor fireplace Internet  \\\n0       0       0               0       0         0                0        0   \n1       1       1               0       0         0                0        1   \n2       1       1               0       0         0                1        1   \n3       0       1               0       0         0                0        1   \n4       1       1               0       0         0                0        1   \n5       1       1               0       0         0                0        0   \n6       1       1               0       0         0                0        1   \n7       0       1               0       1         0                0        1   \n8       0       1               0       0         0                0        0   \n9       0       1               0       0         0                0        0   \n\n  Iron Keypad Kitchen Laptop friendly workspace Lock on bedroom door Lockbox  \\\n0    0      0       1                         0                    0       0   \n1    1      0       1                         1                    1       0   \n2    1      1       1                         1                    1       1   \n3    0      1       1                         0                    0       0   \n4    0      0       1                         0                    0       0   \n5    1      0       1                         0                    0       0   \n6    1      0       1                         1                    1       0   \n7    0      0       1                         0                    0       0   \n8    0      0       0                         1                    0       1   \n9    0      0       0                         1                    1       0   \n\n  Long term stays allowed Luggage dropoff allowed Microwave Oven  \\\n0                       0                       0         0    0   \n1                       0                       0         0    0   \n2                       0                       0         0    0   \n3                       0                       0         0    0   \n4                       0                       0         0    0   \n5                       0                       0         0    0   \n6                       0                       0         0    0   \n7                       0                       0         0    0   \n8                       0                       0         0    0   \n9                       0                       0         0    0   \n\n  Pack ’n Play/travel crib Patio or balcony Pets allowed  \\\n0                        0                0            0   \n1                        0                0            0   \n2                        0                0            0   \n3                        0                0            0   \n4                        0                0            0   \n5                        0                0            0   \n6                        0                0            0   \n7                        0                0            0   \n8                        0                0            1   \n9                        0                0            0   \n\n  Pets live on this property Pool Private entrance Private living room  \\\n0                          0    0                0                   0   \n1                          0    0                0                   0   \n2                          0    0                0                   0   \n3                          0    0                0                   0   \n4                          0    0                0                   0   \n5                          0    0                0                   0   \n6                          1    0                0                   0   \n7                          0    1                0                   0   \n8                          0    0                0                   0   \n9                          0    0                0                   0   \n\n  Refrigerator Room-darkening shades Safety card Self Check-In Shampoo  \\\n0            0                     0           0             0       0   \n1            0                     0           0             0       1   \n2            0                     1           1             1       1   \n3            0                     0           1             1       1   \n4            0                     0           1             0       1   \n5            0                     0           0             0       0   \n6            0                     0           1             1       1   \n7            0                     0           0             0       0   \n8            0                     0           0             1       1   \n9            0                     0           0             0       0   \n\n  Smartlock Smoke detector Smoking allowed Step-free access Stove  \\\n0         0              1               0                0     0   \n1         0              1               0                0     0   \n2         0              1               0                0     0   \n3         0              1               0                0     0   \n4         0              1               0                0     0   \n5         0              1               0                0     0   \n6         0              1               0                0     0   \n7         0              0               0                0     0   \n8         0              1               0                0     0   \n9         0              0               0                0     0   \n\n  Suitable for events TV Washer Well-lit path to entrance  \\\n0                   0  1      1                         0   \n1                   0  1      1                         0   \n2                   0  1      1                         0   \n3                   0  1      1                         0   \n4                   0  1      1                         0   \n5                   0  0      0                         0   \n6                   0  0      0                         0   \n7                   0  1      1                         0   \n8                   0  0      0                         0   \n9                   0  0      0                         0   \n\n  Wheelchair accessible Wireless Internet  \\\n0                     0                 1   \n1                     0                 1   \n2                     0                 1   \n3                     0                 1   \n4                     0                 1   \n5                     0                 1   \n6                     0                 1   \n7                     1                 1   \n8                     0                 1   \n9                     0                 1   \n\n  translation missing: en.hosting_amenity_49  \\\n0                                          0   \n1                                          1   \n2                                          1   \n3                                          0   \n4                                          0   \n5                                          1   \n6                                          0   \n7                                          0   \n8                                          1   \n9                                          1   \n\n  translation missing: en.hosting_amenity_50  am_num bed_type  \\\n0                                          0       7        1   \n1                                          1      22        1   \n2                                          1      29        1   \n3                                          0      18        1   \n4                                          0      18        1   \n5                                          0      10        1   \n6                                          1      24        1   \n7                                          0      17        2   \n8                                          1      14        1   \n9                                          1       7        1   \n\n  cancellation_policy city cleaning_fee host_has_profile_pic  \\\n0                   1    1            1                    1   \n1                   2    2            1                    1   \n2                   2    3            1                    1   \n3                   2    4            1                    1   \n4                   2    3            1                    1   \n5                   1    3            1                    1   \n6                   3    3            1                    1   \n7                   1    1            2                    1   \n8                   2    4            1                    1   \n9                   3    3            1                    1   \n\n  host_identity_verified instant_bookable property_type room_type  \\\n0                      1                1             1         1   \n1                      2                1             2         1   \n2                      1                2             1         1   \n3                      2                2             1         1   \n4                      2                1             1         2   \n5                      2                1             2         1   \n6                      2                2             2         1   \n7                      1                1             1         1   \n8                      1                1             1         1   \n9                      1                1             2         1   \n\n  neighbourhood  host_since  first_review  last_review  host_since_month  \\\n0             1       199.0         199.0        199.0               7.0   \n1             2       192.0         201.0        207.0              12.0   \n2             3       197.0         198.0        212.0               5.0   \n3             4       150.0         171.0        213.0               6.0   \n4             5       183.0         188.0        213.0               3.0   \n5             6       203.0         206.0        213.0              11.0   \n6             7       173.0         185.0        213.0               5.0   \n7             8       128.0           NaN          NaN               8.0   \n8             9       199.0         210.0        213.0               7.0   \n9            10       142.0         156.0        201.0              10.0   \n\n   first_review_month  last_review_month host_since_hot  accommodates  \\\n0                 7.0                7.0              1             6   \n1                 9.0                3.0              1             2   \n2                 6.0                8.0              1             2   \n3                 3.0                9.0              1             2   \n4                 8.0                9.0              1             2   \n5                 2.0                9.0              1             2   \n6                 5.0                9.0              1             2   \n7                 NaN                NaN              1             2   \n8                 6.0                9.0              1             2   \n9                12.0                9.0              1             2   \n\n   bathrooms  bedrooms  beds   latitude   longitude  number_of_reviews  \\\n0        2.0       1.0   4.0  33.788931 -118.154761                  1   \n1        1.0       1.0   1.0  38.934810  -76.978190                  9   \n2        2.0       1.0   1.0  40.695118  -73.926240                 27   \n3        1.0       1.0   1.0  37.796728 -122.411906                 38   \n4        1.0       1.0   1.0  40.785050  -73.974691                  5   \n5        1.0       1.0   1.0  40.640241  -74.015729                  7   \n6        1.5       1.0   1.0  40.676824  -73.915965                 65   \n7        1.0       1.0   1.0  34.068441 -118.353515                  0   \n8        1.0       1.0   1.0  37.801514 -122.411410                 21   \n9        1.0       1.0   1.0  40.751933  -73.878733                 27   \n\n   review_scores_rating  host_response_rate zipcode major_city  population  \\\n0                  60.0                 NaN       1          1       40311   \n1                 100.0                 1.0       2          2       16894   \n2                  83.0                 1.0       3          3       78895   \n3                  95.0                 1.0       4          4       13768   \n4                 100.0                 1.0       5          5       60998   \n5                  94.0                 1.0       6          3       99598   \n6                  91.0                 1.0       7          3       67053   \n7                   NaN                 NaN       8          6       36865   \n8                  87.0                 1.0       9          4        3713   \n9                  88.0                 1.0      10          7       66636   \n\n   population_density  land_area_in_sqmi  water_area_in_sqmi  housing_units  \\\n0             19061.0               2.11                0.00          15792   \n1              5602.0               3.02                0.01           7652   \n2             57033.0               1.38                0.00          31784   \n3             50983.0               0.27                0.00           8843   \n4            124357.0               0.49                0.00          39402   \n5             55603.0               1.79                0.00          31045   \n6             49746.0               1.35                0.00          29074   \n7             14922.0               2.47                0.00          19920   \n8             10791.0               0.34                0.19           2811   \n9             90360.0               0.74                0.00          25100   \n\n   occupied_housing_units  median_home_value  median_household_income  \\\n0                   14556           340600.0                  42672.0   \n1                    7005           355500.0                  52317.0   \n2                   28391           543800.0                  39178.0   \n3                    7628           856900.0                  35427.0   \n4                   34383           872500.0                 103534.0   \n5                   29018           615300.0                  37580.0   \n6                   25693           551900.0                  34492.0   \n7                   18646           945000.0                  71589.0   \n8                    2365           882000.0                  89722.0   \n9                   23906           265500.0                  48683.0   \n\n   word_num  rooms      dis_0          dis_1  occupied_housing_rate    desc_0  \\\n0        76    3.0   0.700424 -6.522993e-166               0.921733 -1.900919   \n1        70    2.0  42.121560  1.061916e+109               0.915447  0.044158   \n2        79    3.0  45.379162   0.000000e+00               0.893248 -0.641935   \n3       183    2.0   5.210855  6.952391e-310               0.862603  0.097897   \n4       172    2.0  45.344551  6.952391e-310               0.872621  0.336234   \n5       158    2.0  45.282600  6.952395e-310               0.934708  0.405066   \n6       170    2.5  45.386642  6.952395e-310               0.883711  0.342457   \n7       169    2.0   0.461243  6.952395e-310               0.936044  0.954821   \n8       178    2.0   5.213975  4.940656e-324               0.841338 -0.410205   \n9       199    2.0  45.434527  3.952525e-323               0.952430 -0.386466   \n\n     desc_1    desc_2    desc_3    desc_4    desc_5    desc_6    desc_7  \\\n0  0.231837 -0.361965 -0.156130 -0.888952 -0.208904 -1.498402 -1.058776   \n1  0.113658 -0.033609 -0.364714  0.567105  0.556047 -0.630063  1.355203   \n2 -0.581967  0.304856  0.081552 -0.437010 -0.088733 -0.844983 -1.084293   \n3 -0.367784 -0.778518 -0.169237  0.165545 -1.182026 -0.726145 -0.224695   \n4 -0.846469  0.236255 -1.909312 -0.199328 -0.774147  0.764652 -0.313032   \n5 -0.069600  0.505565 -1.203447 -0.149615 -1.166468 -0.337233 -0.931331   \n6  0.079571 -1.218456 -0.576328  1.549925 -0.642300 -0.863667  1.474615   \n7  0.034923 -0.484426 -0.159271 -0.555823 -0.253049 -0.051201  0.419002   \n8 -0.229365 -0.309753 -0.854542 -1.072711 -0.790663 -0.362803  0.143501   \n9 -0.415543 -0.790199 -1.334186 -0.155241 -0.885956 -0.106774 -0.759018   \n\n     desc_8    desc_9   desc_10   desc_11   desc_12   desc_13   desc_14  \\\n0 -1.216541  0.651656 -0.626779  0.310452 -0.587204  0.303202  0.293937   \n1  0.906076  1.044096 -0.557932 -0.351208 -0.424376 -0.229480 -0.556773   \n2 -1.057522  1.186769 -0.377836 -0.059716 -0.538127 -0.128097  0.604671   \n3  0.544596 -0.240758  0.234892 -0.255900 -0.238931 -0.209705 -0.756818   \n4 -0.394287  2.670185 -0.197344  0.686809 -1.727731 -0.365483  0.155637   \n5  0.178086  1.163529 -0.758704 -0.880686 -0.544580 -0.066734  1.938759   \n6  0.351032 -0.619935  0.614273 -0.243659 -0.229384  0.006351  0.423398   \n7  0.786326  0.248683 -0.029560  0.030407  0.159311 -0.771203  0.089949   \n8 -0.260168  0.388682  0.108815  0.197395 -0.661643 -0.137759  0.195646   \n9 -0.699641  1.143974 -0.907503  0.162517 -0.153001  0.668408  1.270368   \n\n    desc_15   desc_16   desc_17   desc_18   desc_19   desc_20   desc_21  \\\n0  0.174701  0.426225 -0.731825 -0.458716 -0.847465  0.128600 -0.935357   \n1 -0.920768 -0.316864 -0.651414 -1.711163 -0.016381 -0.703694  0.295607   \n2  0.856488  1.339953 -0.552800 -0.815549 -0.582429  0.276294 -0.460807   \n3 -1.806813 -0.685274 -0.042196  0.533328  0.885913 -1.117236  0.382014   \n4  0.838438  0.079000 -0.701284 -0.723818 -1.423023  0.805489 -0.086649   \n5  0.021058  1.617234 -0.104793  0.920867 -0.345064  0.114559  0.202199   \n6 -1.174113 -0.032415  0.788159  1.123074  0.958812 -0.677423 -0.347228   \n7  0.471646 -1.019550  0.106689 -0.254579 -0.757221  0.022151  0.234992   \n8 -0.651456 -0.336653 -1.017495 -0.829252 -0.849578 -0.161113 -0.826619   \n9  0.499638  0.043442 -0.955577  0.586342 -0.294600 -0.781297 -1.189999   \n\n    desc_22   desc_23   desc_24   desc_25   desc_26   desc_27   desc_28  \\\n0 -1.557620  0.343270 -0.900722  2.083479 -1.143699  0.372548  0.619828   \n1 -0.946121  0.525093 -0.734590  1.056076 -0.226515  0.039734 -0.553441   \n2 -1.868058 -0.178864  0.178433  0.476230 -0.874663 -0.851820  0.760317   \n3 -1.079423  0.035708 -0.904172  0.300797 -0.514923 -0.432467  0.355145   \n4 -0.137798  0.371904 -0.500950  0.408363 -1.084448 -0.031117 -0.620314   \n5 -1.015886  0.694730 -0.644118  1.621285 -0.853773  0.469426  0.293949   \n6 -1.178809 -1.564016 -0.020211  0.492216 -0.823553  1.038746  1.477468   \n7  0.327940  0.927248  0.395764 -0.181856 -0.484569 -0.345169  0.005214   \n8 -1.362941 -0.247913 -0.553381  1.395698 -0.859032 -0.544096 -0.614442   \n9 -1.046400 -0.343633 -0.400559  1.248821 -1.059819  0.478923  0.487110   \n\n    desc_29   desc_30   desc_31   desc_32   desc_33   desc_34   desc_35  \\\n0  1.278649  0.188055  0.684179 -0.713492  1.411318 -0.574032  0.528712   \n1  1.237357  0.458374  0.601546  0.402689  0.694649 -0.346330 -1.309196   \n2  1.059791  0.714377  0.655204 -1.703702 -0.512337  0.115533  0.148635   \n3  0.265456  0.359447  0.548238 -0.258019  1.510483 -0.224177 -0.172252   \n4  0.669138  0.581130  1.149369 -1.273463 -0.366768  0.374153 -0.591189   \n5  0.966986  0.401074  1.459478 -1.357022  3.145036 -0.376560 -0.255110   \n6 -0.141053  1.337039  0.237670 -0.404893  1.521518  0.094889 -0.237682   \n7  0.303876 -0.425588  0.392218 -0.132748 -0.846639  0.294696 -0.874053   \n8  0.698932  0.666913  0.555384 -0.524115  0.821469  0.152502  0.278581   \n9 -0.082268 -0.068191  1.065826 -0.293593  1.016145 -0.429413  0.128414   \n\n    desc_36   desc_37   desc_38   desc_39   desc_40   desc_41   desc_42  \\\n0 -0.978824 -0.493474 -1.327512 -1.043061 -0.318801 -0.975571  0.215525   \n1 -0.088227  1.793174  0.442358 -0.552676  0.271393  0.220107 -0.050281   \n2 -0.494098  0.465845  0.105314  1.105203  0.369854 -1.444038 -0.239121   \n3  1.010828  0.934962  0.084096 -0.662155 -0.346692  0.934905  1.293280   \n4 -0.095716 -0.510410 -0.048973 -0.990633 -0.204771  0.025449 -0.849469   \n5 -0.029341  0.671229 -0.567500 -0.307560 -0.522086 -0.381495  0.175681   \n6  1.249783  0.812284  0.306544 -1.045394  0.513504  0.110728  0.509446   \n7 -0.893368  0.271586 -0.762572  0.064742 -0.932217  1.170915  0.124109   \n8 -0.608494 -0.430915 -0.410455 -0.317834 -0.206240  0.069858 -0.124559   \n9  0.273648  0.489063 -0.543996 -0.574489 -0.456753 -1.731431 -0.363465   \n\n    desc_43   desc_44   desc_45   desc_46   desc_47   desc_48   desc_49  \n0  0.838071  0.070018 -0.534130 -0.801854  0.992161 -0.442845  1.611833  \n1 -0.068751 -0.194533 -0.259209  0.293063 -0.529087 -0.901656 -0.065665  \n2  0.363112 -0.011313 -0.150178 -0.214801 -0.547900 -0.210648  0.672317  \n3  1.525268  0.665803  0.336256  0.468665  0.663039  0.584035 -1.026452  \n4 -1.580561 -0.786989 -0.199927 -0.945691 -0.420864  0.077025  1.162860  \n5  0.743278  1.136454  0.129608 -0.201142 -0.231460 -0.848795  0.659672  \n6  0.427596  0.805039 -0.153877  1.485242  0.253838 -0.373908 -1.828358  \n7 -0.064459 -0.515906 -0.012872 -0.197922 -0.474142  0.615176 -0.597599  \n8 -0.094706 -0.135205 -0.366990 -0.109363 -0.041464  0.216989  0.124994  \n9  0.074568  0.073573 -0.440470  0.647871  1.039814  0.494598  0.717888  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>24-hour check-in</th>\n      <th>Air conditioning</th>\n      <th>Bathtub</th>\n      <th>Bed linens</th>\n      <th>Breakfast</th>\n      <th>Buzzer/wireless intercom</th>\n      <th>Cable TV</th>\n      <th>Carbon monoxide detector</th>\n      <th>Cat(s)</th>\n      <th>Children’s books and toys</th>\n      <th>Coffee maker</th>\n      <th>Cooking basics</th>\n      <th>Dishes and silverware</th>\n      <th>Dishwasher</th>\n      <th>Dog(s)</th>\n      <th>Doorman</th>\n      <th>Dryer</th>\n      <th>Elevator</th>\n      <th>Elevator in building</th>\n      <th>Essentials</th>\n      <th>Extra pillows and blankets</th>\n      <th>Family/kid friendly</th>\n      <th>Fire extinguisher</th>\n      <th>First aid kit</th>\n      <th>Free parking on premises</th>\n      <th>Garden or backyard</th>\n      <th>Gym</th>\n      <th>Hair dryer</th>\n      <th>Hangers</th>\n      <th>Heating</th>\n      <th>Host greets you</th>\n      <th>Hot tub</th>\n      <th>Hot water</th>\n      <th>Indoor fireplace</th>\n      <th>Internet</th>\n      <th>Iron</th>\n      <th>Keypad</th>\n      <th>Kitchen</th>\n      <th>Laptop friendly workspace</th>\n      <th>Lock on bedroom door</th>\n      <th>Lockbox</th>\n      <th>Long term stays allowed</th>\n      <th>Luggage dropoff allowed</th>\n      <th>Microwave</th>\n      <th>Oven</th>\n      <th>Pack ’n Play/travel crib</th>\n      <th>Patio or balcony</th>\n      <th>Pets allowed</th>\n      <th>Pets live on this property</th>\n      <th>Pool</th>\n      <th>Private entrance</th>\n      <th>Private living room</th>\n      <th>Refrigerator</th>\n      <th>Room-darkening shades</th>\n      <th>Safety card</th>\n      <th>Self Check-In</th>\n      <th>Shampoo</th>\n      <th>Smartlock</th>\n      <th>Smoke detector</th>\n      <th>Smoking allowed</th>\n      <th>Step-free access</th>\n      <th>Stove</th>\n      <th>Suitable for events</th>\n      <th>TV</th>\n      <th>Washer</th>\n      <th>Well-lit path to entrance</th>\n      <th>Wheelchair accessible</th>\n      <th>Wireless Internet</th>\n      <th>translation missing: en.hosting_amenity_49</th>\n      <th>translation missing: en.hosting_amenity_50</th>\n      <th>am_num</th>\n      <th>bed_type</th>\n      <th>cancellation_policy</th>\n      <th>city</th>\n      <th>cleaning_fee</th>\n      <th>host_has_profile_pic</th>\n      <th>host_identity_verified</th>\n      <th>instant_bookable</th>\n      <th>property_type</th>\n      <th>room_type</th>\n      <th>neighbourhood</th>\n      <th>host_since</th>\n      <th>first_review</th>\n      <th>last_review</th>\n      <th>host_since_month</th>\n      <th>first_review_month</th>\n      <th>last_review_month</th>\n      <th>host_since_hot</th>\n      <th>accommodates</th>\n      <th>bathrooms</th>\n      <th>bedrooms</th>\n      <th>beds</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>number_of_reviews</th>\n      <th>review_scores_rating</th>\n      <th>host_response_rate</th>\n      <th>zipcode</th>\n      <th>major_city</th>\n      <th>population</th>\n      <th>population_density</th>\n      <th>land_area_in_sqmi</th>\n      <th>water_area_in_sqmi</th>\n      <th>housing_units</th>\n      <th>occupied_housing_units</th>\n      <th>median_home_value</th>\n      <th>median_household_income</th>\n      <th>word_num</th>\n      <th>rooms</th>\n      <th>dis_0</th>\n      <th>dis_1</th>\n      <th>occupied_housing_rate</th>\n      <th>desc_0</th>\n      <th>desc_1</th>\n      <th>desc_2</th>\n      <th>desc_3</th>\n      <th>desc_4</th>\n      <th>desc_5</th>\n      <th>desc_6</th>\n      <th>desc_7</th>\n      <th>desc_8</th>\n      <th>desc_9</th>\n      <th>desc_10</th>\n      <th>desc_11</th>\n      <th>desc_12</th>\n      <th>desc_13</th>\n      <th>desc_14</th>\n      <th>desc_15</th>\n      <th>desc_16</th>\n      <th>desc_17</th>\n      <th>desc_18</th>\n      <th>desc_19</th>\n      <th>desc_20</th>\n      <th>desc_21</th>\n      <th>desc_22</th>\n      <th>desc_23</th>\n      <th>desc_24</th>\n      <th>desc_25</th>\n      <th>desc_26</th>\n      <th>desc_27</th>\n      <th>desc_28</th>\n      <th>desc_29</th>\n      <th>desc_30</th>\n      <th>desc_31</th>\n      <th>desc_32</th>\n      <th>desc_33</th>\n      <th>desc_34</th>\n      <th>desc_35</th>\n      <th>desc_36</th>\n      <th>desc_37</th>\n      <th>desc_38</th>\n      <th>desc_39</th>\n      <th>desc_40</th>\n      <th>desc_41</th>\n      <th>desc_42</th>\n      <th>desc_43</th>\n      <th>desc_44</th>\n      <th>desc_45</th>\n      <th>desc_46</th>\n      <th>desc_47</th>\n      <th>desc_48</th>\n      <th>desc_49</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>199.0</td>\n      <td>199.0</td>\n      <td>199.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>33.788931</td>\n      <td>-118.154761</td>\n      <td>1</td>\n      <td>60.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>40311</td>\n      <td>19061.0</td>\n      <td>2.11</td>\n      <td>0.00</td>\n      <td>15792</td>\n      <td>14556</td>\n      <td>340600.0</td>\n      <td>42672.0</td>\n      <td>76</td>\n      <td>3.0</td>\n      <td>0.700424</td>\n      <td>-6.522993e-166</td>\n      <td>0.921733</td>\n      <td>-1.900919</td>\n      <td>0.231837</td>\n      <td>-0.361965</td>\n      <td>-0.156130</td>\n      <td>-0.888952</td>\n      <td>-0.208904</td>\n      <td>-1.498402</td>\n      <td>-1.058776</td>\n      <td>-1.216541</td>\n      <td>0.651656</td>\n      <td>-0.626779</td>\n      <td>0.310452</td>\n      <td>-0.587204</td>\n      <td>0.303202</td>\n      <td>0.293937</td>\n      <td>0.174701</td>\n      <td>0.426225</td>\n      <td>-0.731825</td>\n      <td>-0.458716</td>\n      <td>-0.847465</td>\n      <td>0.128600</td>\n      <td>-0.935357</td>\n      <td>-1.557620</td>\n      <td>0.343270</td>\n      <td>-0.900722</td>\n      <td>2.083479</td>\n      <td>-1.143699</td>\n      <td>0.372548</td>\n      <td>0.619828</td>\n      <td>1.278649</td>\n      <td>0.188055</td>\n      <td>0.684179</td>\n      <td>-0.713492</td>\n      <td>1.411318</td>\n      <td>-0.574032</td>\n      <td>0.528712</td>\n      <td>-0.978824</td>\n      <td>-0.493474</td>\n      <td>-1.327512</td>\n      <td>-1.043061</td>\n      <td>-0.318801</td>\n      <td>-0.975571</td>\n      <td>0.215525</td>\n      <td>0.838071</td>\n      <td>0.070018</td>\n      <td>-0.534130</td>\n      <td>-0.801854</td>\n      <td>0.992161</td>\n      <td>-0.442845</td>\n      <td>1.611833</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>192.0</td>\n      <td>201.0</td>\n      <td>207.0</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>38.934810</td>\n      <td>-76.978190</td>\n      <td>9</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>16894</td>\n      <td>5602.0</td>\n      <td>3.02</td>\n      <td>0.01</td>\n      <td>7652</td>\n      <td>7005</td>\n      <td>355500.0</td>\n      <td>52317.0</td>\n      <td>70</td>\n      <td>2.0</td>\n      <td>42.121560</td>\n      <td>1.061916e+109</td>\n      <td>0.915447</td>\n      <td>0.044158</td>\n      <td>0.113658</td>\n      <td>-0.033609</td>\n      <td>-0.364714</td>\n      <td>0.567105</td>\n      <td>0.556047</td>\n      <td>-0.630063</td>\n      <td>1.355203</td>\n      <td>0.906076</td>\n      <td>1.044096</td>\n      <td>-0.557932</td>\n      <td>-0.351208</td>\n      <td>-0.424376</td>\n      <td>-0.229480</td>\n      <td>-0.556773</td>\n      <td>-0.920768</td>\n      <td>-0.316864</td>\n      <td>-0.651414</td>\n      <td>-1.711163</td>\n      <td>-0.016381</td>\n      <td>-0.703694</td>\n      <td>0.295607</td>\n      <td>-0.946121</td>\n      <td>0.525093</td>\n      <td>-0.734590</td>\n      <td>1.056076</td>\n      <td>-0.226515</td>\n      <td>0.039734</td>\n      <td>-0.553441</td>\n      <td>1.237357</td>\n      <td>0.458374</td>\n      <td>0.601546</td>\n      <td>0.402689</td>\n      <td>0.694649</td>\n      <td>-0.346330</td>\n      <td>-1.309196</td>\n      <td>-0.088227</td>\n      <td>1.793174</td>\n      <td>0.442358</td>\n      <td>-0.552676</td>\n      <td>0.271393</td>\n      <td>0.220107</td>\n      <td>-0.050281</td>\n      <td>-0.068751</td>\n      <td>-0.194533</td>\n      <td>-0.259209</td>\n      <td>0.293063</td>\n      <td>-0.529087</td>\n      <td>-0.901656</td>\n      <td>-0.065665</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>29</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>197.0</td>\n      <td>198.0</td>\n      <td>212.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>8.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>40.695118</td>\n      <td>-73.926240</td>\n      <td>27</td>\n      <td>83.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>78895</td>\n      <td>57033.0</td>\n      <td>1.38</td>\n      <td>0.00</td>\n      <td>31784</td>\n      <td>28391</td>\n      <td>543800.0</td>\n      <td>39178.0</td>\n      <td>79</td>\n      <td>3.0</td>\n      <td>45.379162</td>\n      <td>0.000000e+00</td>\n      <td>0.893248</td>\n      <td>-0.641935</td>\n      <td>-0.581967</td>\n      <td>0.304856</td>\n      <td>0.081552</td>\n      <td>-0.437010</td>\n      <td>-0.088733</td>\n      <td>-0.844983</td>\n      <td>-1.084293</td>\n      <td>-1.057522</td>\n      <td>1.186769</td>\n      <td>-0.377836</td>\n      <td>-0.059716</td>\n      <td>-0.538127</td>\n      <td>-0.128097</td>\n      <td>0.604671</td>\n      <td>0.856488</td>\n      <td>1.339953</td>\n      <td>-0.552800</td>\n      <td>-0.815549</td>\n      <td>-0.582429</td>\n      <td>0.276294</td>\n      <td>-0.460807</td>\n      <td>-1.868058</td>\n      <td>-0.178864</td>\n      <td>0.178433</td>\n      <td>0.476230</td>\n      <td>-0.874663</td>\n      <td>-0.851820</td>\n      <td>0.760317</td>\n      <td>1.059791</td>\n      <td>0.714377</td>\n      <td>0.655204</td>\n      <td>-1.703702</td>\n      <td>-0.512337</td>\n      <td>0.115533</td>\n      <td>0.148635</td>\n      <td>-0.494098</td>\n      <td>0.465845</td>\n      <td>0.105314</td>\n      <td>1.105203</td>\n      <td>0.369854</td>\n      <td>-1.444038</td>\n      <td>-0.239121</td>\n      <td>0.363112</td>\n      <td>-0.011313</td>\n      <td>-0.150178</td>\n      <td>-0.214801</td>\n      <td>-0.547900</td>\n      <td>-0.210648</td>\n      <td>0.672317</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>150.0</td>\n      <td>171.0</td>\n      <td>213.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>37.796728</td>\n      <td>-122.411906</td>\n      <td>38</td>\n      <td>95.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>13768</td>\n      <td>50983.0</td>\n      <td>0.27</td>\n      <td>0.00</td>\n      <td>8843</td>\n      <td>7628</td>\n      <td>856900.0</td>\n      <td>35427.0</td>\n      <td>183</td>\n      <td>2.0</td>\n      <td>5.210855</td>\n      <td>6.952391e-310</td>\n      <td>0.862603</td>\n      <td>0.097897</td>\n      <td>-0.367784</td>\n      <td>-0.778518</td>\n      <td>-0.169237</td>\n      <td>0.165545</td>\n      <td>-1.182026</td>\n      <td>-0.726145</td>\n      <td>-0.224695</td>\n      <td>0.544596</td>\n      <td>-0.240758</td>\n      <td>0.234892</td>\n      <td>-0.255900</td>\n      <td>-0.238931</td>\n      <td>-0.209705</td>\n      <td>-0.756818</td>\n      <td>-1.806813</td>\n      <td>-0.685274</td>\n      <td>-0.042196</td>\n      <td>0.533328</td>\n      <td>0.885913</td>\n      <td>-1.117236</td>\n      <td>0.382014</td>\n      <td>-1.079423</td>\n      <td>0.035708</td>\n      <td>-0.904172</td>\n      <td>0.300797</td>\n      <td>-0.514923</td>\n      <td>-0.432467</td>\n      <td>0.355145</td>\n      <td>0.265456</td>\n      <td>0.359447</td>\n      <td>0.548238</td>\n      <td>-0.258019</td>\n      <td>1.510483</td>\n      <td>-0.224177</td>\n      <td>-0.172252</td>\n      <td>1.010828</td>\n      <td>0.934962</td>\n      <td>0.084096</td>\n      <td>-0.662155</td>\n      <td>-0.346692</td>\n      <td>0.934905</td>\n      <td>1.293280</td>\n      <td>1.525268</td>\n      <td>0.665803</td>\n      <td>0.336256</td>\n      <td>0.468665</td>\n      <td>0.663039</td>\n      <td>0.584035</td>\n      <td>-1.026452</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>183.0</td>\n      <td>188.0</td>\n      <td>213.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>40.785050</td>\n      <td>-73.974691</td>\n      <td>5</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>60998</td>\n      <td>124357.0</td>\n      <td>0.49</td>\n      <td>0.00</td>\n      <td>39402</td>\n      <td>34383</td>\n      <td>872500.0</td>\n      <td>103534.0</td>\n      <td>172</td>\n      <td>2.0</td>\n      <td>45.344551</td>\n      <td>6.952391e-310</td>\n      <td>0.872621</td>\n      <td>0.336234</td>\n      <td>-0.846469</td>\n      <td>0.236255</td>\n      <td>-1.909312</td>\n      <td>-0.199328</td>\n      <td>-0.774147</td>\n      <td>0.764652</td>\n      <td>-0.313032</td>\n      <td>-0.394287</td>\n      <td>2.670185</td>\n      <td>-0.197344</td>\n      <td>0.686809</td>\n      <td>-1.727731</td>\n      <td>-0.365483</td>\n      <td>0.155637</td>\n      <td>0.838438</td>\n      <td>0.079000</td>\n      <td>-0.701284</td>\n      <td>-0.723818</td>\n      <td>-1.423023</td>\n      <td>0.805489</td>\n      <td>-0.086649</td>\n      <td>-0.137798</td>\n      <td>0.371904</td>\n      <td>-0.500950</td>\n      <td>0.408363</td>\n      <td>-1.084448</td>\n      <td>-0.031117</td>\n      <td>-0.620314</td>\n      <td>0.669138</td>\n      <td>0.581130</td>\n      <td>1.149369</td>\n      <td>-1.273463</td>\n      <td>-0.366768</td>\n      <td>0.374153</td>\n      <td>-0.591189</td>\n      <td>-0.095716</td>\n      <td>-0.510410</td>\n      <td>-0.048973</td>\n      <td>-0.990633</td>\n      <td>-0.204771</td>\n      <td>0.025449</td>\n      <td>-0.849469</td>\n      <td>-1.580561</td>\n      <td>-0.786989</td>\n      <td>-0.199927</td>\n      <td>-0.945691</td>\n      <td>-0.420864</td>\n      <td>0.077025</td>\n      <td>1.162860</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>6</td>\n      <td>203.0</td>\n      <td>206.0</td>\n      <td>213.0</td>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>40.640241</td>\n      <td>-74.015729</td>\n      <td>7</td>\n      <td>94.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>99598</td>\n      <td>55603.0</td>\n      <td>1.79</td>\n      <td>0.00</td>\n      <td>31045</td>\n      <td>29018</td>\n      <td>615300.0</td>\n      <td>37580.0</td>\n      <td>158</td>\n      <td>2.0</td>\n      <td>45.282600</td>\n      <td>6.952395e-310</td>\n      <td>0.934708</td>\n      <td>0.405066</td>\n      <td>-0.069600</td>\n      <td>0.505565</td>\n      <td>-1.203447</td>\n      <td>-0.149615</td>\n      <td>-1.166468</td>\n      <td>-0.337233</td>\n      <td>-0.931331</td>\n      <td>0.178086</td>\n      <td>1.163529</td>\n      <td>-0.758704</td>\n      <td>-0.880686</td>\n      <td>-0.544580</td>\n      <td>-0.066734</td>\n      <td>1.938759</td>\n      <td>0.021058</td>\n      <td>1.617234</td>\n      <td>-0.104793</td>\n      <td>0.920867</td>\n      <td>-0.345064</td>\n      <td>0.114559</td>\n      <td>0.202199</td>\n      <td>-1.015886</td>\n      <td>0.694730</td>\n      <td>-0.644118</td>\n      <td>1.621285</td>\n      <td>-0.853773</td>\n      <td>0.469426</td>\n      <td>0.293949</td>\n      <td>0.966986</td>\n      <td>0.401074</td>\n      <td>1.459478</td>\n      <td>-1.357022</td>\n      <td>3.145036</td>\n      <td>-0.376560</td>\n      <td>-0.255110</td>\n      <td>-0.029341</td>\n      <td>0.671229</td>\n      <td>-0.567500</td>\n      <td>-0.307560</td>\n      <td>-0.522086</td>\n      <td>-0.381495</td>\n      <td>0.175681</td>\n      <td>0.743278</td>\n      <td>1.136454</td>\n      <td>0.129608</td>\n      <td>-0.201142</td>\n      <td>-0.231460</td>\n      <td>-0.848795</td>\n      <td>0.659672</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>24</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>173.0</td>\n      <td>185.0</td>\n      <td>213.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.5</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>40.676824</td>\n      <td>-73.915965</td>\n      <td>65</td>\n      <td>91.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>67053</td>\n      <td>49746.0</td>\n      <td>1.35</td>\n      <td>0.00</td>\n      <td>29074</td>\n      <td>25693</td>\n      <td>551900.0</td>\n      <td>34492.0</td>\n      <td>170</td>\n      <td>2.5</td>\n      <td>45.386642</td>\n      <td>6.952395e-310</td>\n      <td>0.883711</td>\n      <td>0.342457</td>\n      <td>0.079571</td>\n      <td>-1.218456</td>\n      <td>-0.576328</td>\n      <td>1.549925</td>\n      <td>-0.642300</td>\n      <td>-0.863667</td>\n      <td>1.474615</td>\n      <td>0.351032</td>\n      <td>-0.619935</td>\n      <td>0.614273</td>\n      <td>-0.243659</td>\n      <td>-0.229384</td>\n      <td>0.006351</td>\n      <td>0.423398</td>\n      <td>-1.174113</td>\n      <td>-0.032415</td>\n      <td>0.788159</td>\n      <td>1.123074</td>\n      <td>0.958812</td>\n      <td>-0.677423</td>\n      <td>-0.347228</td>\n      <td>-1.178809</td>\n      <td>-1.564016</td>\n      <td>-0.020211</td>\n      <td>0.492216</td>\n      <td>-0.823553</td>\n      <td>1.038746</td>\n      <td>1.477468</td>\n      <td>-0.141053</td>\n      <td>1.337039</td>\n      <td>0.237670</td>\n      <td>-0.404893</td>\n      <td>1.521518</td>\n      <td>0.094889</td>\n      <td>-0.237682</td>\n      <td>1.249783</td>\n      <td>0.812284</td>\n      <td>0.306544</td>\n      <td>-1.045394</td>\n      <td>0.513504</td>\n      <td>0.110728</td>\n      <td>0.509446</td>\n      <td>0.427596</td>\n      <td>0.805039</td>\n      <td>-0.153877</td>\n      <td>1.485242</td>\n      <td>0.253838</td>\n      <td>-0.373908</td>\n      <td>-1.828358</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n      <td>128.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>34.068441</td>\n      <td>-118.353515</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>6</td>\n      <td>36865</td>\n      <td>14922.0</td>\n      <td>2.47</td>\n      <td>0.00</td>\n      <td>19920</td>\n      <td>18646</td>\n      <td>945000.0</td>\n      <td>71589.0</td>\n      <td>169</td>\n      <td>2.0</td>\n      <td>0.461243</td>\n      <td>6.952395e-310</td>\n      <td>0.936044</td>\n      <td>0.954821</td>\n      <td>0.034923</td>\n      <td>-0.484426</td>\n      <td>-0.159271</td>\n      <td>-0.555823</td>\n      <td>-0.253049</td>\n      <td>-0.051201</td>\n      <td>0.419002</td>\n      <td>0.786326</td>\n      <td>0.248683</td>\n      <td>-0.029560</td>\n      <td>0.030407</td>\n      <td>0.159311</td>\n      <td>-0.771203</td>\n      <td>0.089949</td>\n      <td>0.471646</td>\n      <td>-1.019550</td>\n      <td>0.106689</td>\n      <td>-0.254579</td>\n      <td>-0.757221</td>\n      <td>0.022151</td>\n      <td>0.234992</td>\n      <td>0.327940</td>\n      <td>0.927248</td>\n      <td>0.395764</td>\n      <td>-0.181856</td>\n      <td>-0.484569</td>\n      <td>-0.345169</td>\n      <td>0.005214</td>\n      <td>0.303876</td>\n      <td>-0.425588</td>\n      <td>0.392218</td>\n      <td>-0.132748</td>\n      <td>-0.846639</td>\n      <td>0.294696</td>\n      <td>-0.874053</td>\n      <td>-0.893368</td>\n      <td>0.271586</td>\n      <td>-0.762572</td>\n      <td>0.064742</td>\n      <td>-0.932217</td>\n      <td>1.170915</td>\n      <td>0.124109</td>\n      <td>-0.064459</td>\n      <td>-0.515906</td>\n      <td>-0.012872</td>\n      <td>-0.197922</td>\n      <td>-0.474142</td>\n      <td>0.615176</td>\n      <td>-0.597599</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>199.0</td>\n      <td>210.0</td>\n      <td>213.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>37.801514</td>\n      <td>-122.411410</td>\n      <td>21</td>\n      <td>87.0</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>4</td>\n      <td>3713</td>\n      <td>10791.0</td>\n      <td>0.34</td>\n      <td>0.19</td>\n      <td>2811</td>\n      <td>2365</td>\n      <td>882000.0</td>\n      <td>89722.0</td>\n      <td>178</td>\n      <td>2.0</td>\n      <td>5.213975</td>\n      <td>4.940656e-324</td>\n      <td>0.841338</td>\n      <td>-0.410205</td>\n      <td>-0.229365</td>\n      <td>-0.309753</td>\n      <td>-0.854542</td>\n      <td>-1.072711</td>\n      <td>-0.790663</td>\n      <td>-0.362803</td>\n      <td>0.143501</td>\n      <td>-0.260168</td>\n      <td>0.388682</td>\n      <td>0.108815</td>\n      <td>0.197395</td>\n      <td>-0.661643</td>\n      <td>-0.137759</td>\n      <td>0.195646</td>\n      <td>-0.651456</td>\n      <td>-0.336653</td>\n      <td>-1.017495</td>\n      <td>-0.829252</td>\n      <td>-0.849578</td>\n      <td>-0.161113</td>\n      <td>-0.826619</td>\n      <td>-1.362941</td>\n      <td>-0.247913</td>\n      <td>-0.553381</td>\n      <td>1.395698</td>\n      <td>-0.859032</td>\n      <td>-0.544096</td>\n      <td>-0.614442</td>\n      <td>0.698932</td>\n      <td>0.666913</td>\n      <td>0.555384</td>\n      <td>-0.524115</td>\n      <td>0.821469</td>\n      <td>0.152502</td>\n      <td>0.278581</td>\n      <td>-0.608494</td>\n      <td>-0.430915</td>\n      <td>-0.410455</td>\n      <td>-0.317834</td>\n      <td>-0.206240</td>\n      <td>0.069858</td>\n      <td>-0.124559</td>\n      <td>-0.094706</td>\n      <td>-0.135205</td>\n      <td>-0.366990</td>\n      <td>-0.109363</td>\n      <td>-0.041464</td>\n      <td>0.216989</td>\n      <td>0.124994</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>10</td>\n      <td>142.0</td>\n      <td>156.0</td>\n      <td>201.0</td>\n      <td>10.0</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>40.751933</td>\n      <td>-73.878733</td>\n      <td>27</td>\n      <td>88.0</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>7</td>\n      <td>66636</td>\n      <td>90360.0</td>\n      <td>0.74</td>\n      <td>0.00</td>\n      <td>25100</td>\n      <td>23906</td>\n      <td>265500.0</td>\n      <td>48683.0</td>\n      <td>199</td>\n      <td>2.0</td>\n      <td>45.434527</td>\n      <td>3.952525e-323</td>\n      <td>0.952430</td>\n      <td>-0.386466</td>\n      <td>-0.415543</td>\n      <td>-0.790199</td>\n      <td>-1.334186</td>\n      <td>-0.155241</td>\n      <td>-0.885956</td>\n      <td>-0.106774</td>\n      <td>-0.759018</td>\n      <td>-0.699641</td>\n      <td>1.143974</td>\n      <td>-0.907503</td>\n      <td>0.162517</td>\n      <td>-0.153001</td>\n      <td>0.668408</td>\n      <td>1.270368</td>\n      <td>0.499638</td>\n      <td>0.043442</td>\n      <td>-0.955577</td>\n      <td>0.586342</td>\n      <td>-0.294600</td>\n      <td>-0.781297</td>\n      <td>-1.189999</td>\n      <td>-1.046400</td>\n      <td>-0.343633</td>\n      <td>-0.400559</td>\n      <td>1.248821</td>\n      <td>-1.059819</td>\n      <td>0.478923</td>\n      <td>0.487110</td>\n      <td>-0.082268</td>\n      <td>-0.068191</td>\n      <td>1.065826</td>\n      <td>-0.293593</td>\n      <td>1.016145</td>\n      <td>-0.429413</td>\n      <td>0.128414</td>\n      <td>0.273648</td>\n      <td>0.489063</td>\n      <td>-0.543996</td>\n      <td>-0.574489</td>\n      <td>-0.456753</td>\n      <td>-1.731431</td>\n      <td>-0.363465</td>\n      <td>0.074568</td>\n      <td>0.073573</td>\n      <td>-0.440470</td>\n      <td>0.647871</td>\n      <td>1.039814</td>\n      <td>0.494598</td>\n      <td>0.717888</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 800)\n",
    "display(train_X_df.head(5))\n",
    "print(train_X_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60 (658)\ttotal: 3m 18s\tremaining: 37.2s\n",
      "842:\tlearn: 77.3369845\ttest: 99.2745396\tbest: 99.1285460 (658)\ttotal: 3m 18s\tremaining: 37s\n",
      "843:\tlearn: 77.3332779\ttest: 99.2755531\tbest: 99.1285460 (658)\ttotal: 3m 18s\tremaining: 36.7s\n",
      "844:\tlearn: 77.3237808\ttest: 99.2777809\tbest: 99.1285460 (658)\ttotal: 3m 19s\tremaining: 36.5s\n",
      "845:\tlearn: 77.3101861\ttest: 99.2791128\tbest: 99.1285460 (658)\ttotal: 3m 19s\tremaining: 36.3s\n",
      "846:\tlearn: 77.2951691\ttest: 99.2759221\tbest: 99.1285460 (658)\ttotal: 3m 19s\tremaining: 36s\n",
      "847:\tlearn: 77.2536982\ttest: 99.2847200\tbest: 99.1285460 (658)\ttotal: 3m 19s\tremaining: 35.8s\n",
      "848:\tlearn: 77.2336665\ttest: 99.2777741\tbest: 99.1285460 (658)\ttotal: 3m 19s\tremaining: 35.5s\n",
      "849:\tlearn: 77.2091788\ttest: 99.2646954\tbest: 99.1285460 (658)\ttotal: 3m 20s\tremaining: 35.3s\n",
      "850:\tlearn: 77.1977737\ttest: 99.2768809\tbest: 99.1285460 (658)\ttotal: 3m 20s\tremaining: 35.1s\n",
      "851:\tlearn: 77.1831332\ttest: 99.2805788\tbest: 99.1285460 (658)\ttotal: 3m 20s\tremaining: 34.9s\n",
      "852:\tlearn: 77.1539492\ttest: 99.2898560\tbest: 99.1285460 (658)\ttotal: 3m 20s\tremaining: 34.6s\n",
      "853:\tlearn: 77.1393557\ttest: 99.2967513\tbest: 99.1285460 (658)\ttotal: 3m 21s\tremaining: 34.4s\n",
      "854:\tlearn: 77.1293714\ttest: 99.2993278\tbest: 99.1285460 (658)\ttotal: 3m 21s\tremaining: 34.2s\n",
      "855:\tlearn: 77.1009111\ttest: 99.2972883\tbest: 99.1285460 (658)\ttotal: 3m 21s\tremaining: 34s\n",
      "856:\tlearn: 77.0863559\ttest: 99.2913071\tbest: 99.1285460 (658)\ttotal: 3m 22s\tremaining: 33.8s\n",
      "857:\tlearn: 77.0701428\ttest: 99.2902239\tbest: 99.1285460 (658)\ttotal: 3m 22s\tremaining: 33.5s\n",
      "858:\tlearn: 77.0556789\ttest: 99.2799504\tbest: 99.1285460 (658)\ttotal: 3m 22s\tremaining: 33.3s\n",
      "859:\tlearn: 77.0386697\ttest: 99.2697010\tbest: 99.1285460 (658)\ttotal: 3m 23s\tremaining: 33.1s\n",
      "860:\tlearn: 77.0094895\ttest: 99.2823643\tbest: 99.1285460 (658)\ttotal: 3m 23s\tremaining: 32.8s\n",
      "861:\tlearn: 76.9808847\ttest: 99.2726119\tbest: 99.1285460 (658)\ttotal: 3m 23s\tremaining: 32.6s\n",
      "862:\tlearn: 76.9687667\ttest: 99.2679401\tbest: 99.1285460 (658)\ttotal: 3m 23s\tremaining: 32.3s\n",
      "863:\tlearn: 76.9520872\ttest: 99.2638091\tbest: 99.1285460 (658)\ttotal: 3m 23s\tremaining: 32.1s\n",
      "864:\tlearn: 76.9113963\ttest: 99.2627290\tbest: 99.1285460 (658)\ttotal: 3m 24s\tremaining: 31.9s\n",
      "865:\tlearn: 76.8817788\ttest: 99.2530864\tbest: 99.1285460 (658)\ttotal: 3m 24s\tremaining: 31.6s\n",
      "866:\tlearn: 76.8797954\ttest: 99.2522628\tbest: 99.1285460 (658)\ttotal: 3m 24s\tremaining: 31.4s\n",
      "867:\tlearn: 76.8541855\ttest: 99.2453436\tbest: 99.1285460 (658)\ttotal: 3m 24s\tremaining: 31.2s\n",
      "868:\tlearn: 76.8240531\ttest: 99.2223642\tbest: 99.1285460 (658)\ttotal: 3m 25s\tremaining: 30.9s\n",
      "869:\tlearn: 76.8174943\ttest: 99.2195353\tbest: 99.1285460 (658)\ttotal: 3m 25s\tremaining: 30.7s\n",
      "870:\tlearn: 76.7946624\ttest: 99.2236528\tbest: 99.1285460 (658)\ttotal: 3m 25s\tremaining: 30.5s\n",
      "871:\tlearn: 76.7754180\ttest: 99.1910193\tbest: 99.1285460 (658)\ttotal: 3m 26s\tremaining: 30.3s\n",
      "872:\tlearn: 76.7568687\ttest: 99.1924359\tbest: 99.1285460 (658)\ttotal: 3m 26s\tremaining: 30s\n",
      "873:\tlearn: 76.7568636\ttest: 99.1925685\tbest: 99.1285460 (658)\ttotal: 3m 26s\tremaining: 29.8s\n",
      "874:\tlearn: 76.7350952\ttest: 99.1895465\tbest: 99.1285460 (658)\ttotal: 3m 26s\tremaining: 29.6s\n",
      "875:\tlearn: 76.6947140\ttest: 99.1809720\tbest: 99.1285460 (658)\ttotal: 3m 27s\tremaining: 29.3s\n",
      "876:\tlearn: 76.6793493\ttest: 99.1814417\tbest: 99.1285460 (658)\ttotal: 3m 27s\tremaining: 29.1s\n",
      "877:\tlearn: 76.6415010\ttest: 99.1906276\tbest: 99.1285460 (658)\ttotal: 3m 27s\tremaining: 28.8s\n",
      "878:\tlearn: 76.6229537\ttest: 99.1938115\tbest: 99.1285460 (658)\ttotal: 3m 27s\tremaining: 28.6s\n",
      "879:\tlearn: 76.6127401\ttest: 99.1922901\tbest: 99.1285460 (658)\ttotal: 3m 28s\tremaining: 28.4s\n",
      "880:\tlearn: 76.5669083\ttest: 99.1867522\tbest: 99.1285460 (658)\ttotal: 3m 28s\tremaining: 28.1s\n",
      "881:\tlearn: 76.5360652\ttest: 99.1790263\tbest: 99.1285460 (658)\ttotal: 3m 28s\tremaining: 27.9s\n",
      "882:\tlearn: 76.4735770\ttest: 99.1795896\tbest: 99.1285460 (658)\ttotal: 3m 28s\tremaining: 27.7s\n",
      "883:\tlearn: 76.4630991\ttest: 99.1751645\tbest: 99.1285460 (658)\ttotal: 3m 29s\tremaining: 27.4s\n",
      "884:\tlearn: 76.4537812\ttest: 99.1783486\tbest: 99.1285460 (658)\ttotal: 3m 29s\tremaining: 27.2s\n",
      "885:\tlearn: 76.4416227\ttest: 99.1755401\tbest: 99.1285460 (658)\ttotal: 3m 29s\tremaining: 27s\n",
      "886:\tlearn: 76.4355298\ttest: 99.1850440\tbest: 99.1285460 (658)\ttotal: 3m 29s\tremaining: 26.7s\n",
      "887:\tlearn: 76.4181830\ttest: 99.1770071\tbest: 99.1285460 (658)\ttotal: 3m 29s\tremaining: 26.5s\n",
      "888:\tlearn: 76.4156920\ttest: 99.1766122\tbest: 99.1285460 (658)\ttotal: 3m 30s\tremaining: 26.2s\n",
      "889:\tlearn: 76.3875914\ttest: 99.1406472\tbest: 99.1285460 (658)\ttotal: 3m 30s\tremaining: 26s\n",
      "890:\tlearn: 76.3692629\ttest: 99.1332258\tbest: 99.1285460 (658)\ttotal: 3m 30s\tremaining: 25.8s\n",
      "891:\tlearn: 76.3281339\ttest: 99.1364921\tbest: 99.1285460 (658)\ttotal: 3m 30s\tremaining: 25.5s\n",
      "892:\tlearn: 76.3075979\ttest: 99.1265154\tbest: 99.1265154 (892)\ttotal: 3m 31s\tremaining: 25.3s\n",
      "893:\tlearn: 76.2948401\ttest: 99.1312065\tbest: 99.1265154 (892)\ttotal: 3m 31s\tremaining: 25.1s\n",
      "894:\tlearn: 76.2796836\ttest: 99.1304559\tbest: 99.1265154 (892)\ttotal: 3m 31s\tremaining: 24.8s\n",
      "895:\tlearn: 76.2561471\ttest: 99.1270264\tbest: 99.1265154 (892)\ttotal: 3m 31s\tremaining: 24.6s\n",
      "896:\tlearn: 76.2225442\ttest: 99.1194941\tbest: 99.1194941 (896)\ttotal: 3m 32s\tremaining: 24.3s\n",
      "897:\tlearn: 76.1976693\ttest: 99.1227391\tbest: 99.1194941 (896)\ttotal: 3m 32s\tremaining: 24.1s\n",
      "898:\tlearn: 76.1717542\ttest: 99.1220984\tbest: 99.1194941 (896)\ttotal: 3m 32s\tremaining: 23.9s\n",
      "899:\tlearn: 76.1620160\ttest: 99.1250045\tbest: 99.1194941 (896)\ttotal: 3m 32s\tremaining: 23.6s\n",
      "900:\tlearn: 76.1344412\ttest: 99.0987238\tbest: 99.0987238 (900)\ttotal: 3m 32s\tremaining: 23.4s\n",
      "901:\tlearn: 76.1308912\ttest: 99.1006390\tbest: 99.0987238 (900)\ttotal: 3m 33s\tremaining: 23.2s\n",
      "902:\tlearn: 76.1118802\ttest: 99.0982639\tbest: 99.0982639 (902)\ttotal: 3m 33s\tremaining: 22.9s\n",
      "903:\tlearn: 76.0946692\ttest: 99.0955381\tbest: 99.0955381 (903)\ttotal: 3m 33s\tremaining: 22.7s\n",
      "904:\tlearn: 76.0621705\ttest: 99.0957428\tbest: 99.0955381 (903)\ttotal: 3m 33s\tremaining: 22.4s\n",
      "905:\tlearn: 76.0577700\ttest: 99.0957572\tbest: 99.0955381 (903)\ttotal: 3m 33s\tremaining: 22.2s\n",
      "906:\tlearn: 76.0375459\ttest: 99.1046065\tbest: 99.0955381 (903)\ttotal: 3m 34s\tremaining: 22s\n",
      "907:\tlearn: 76.0260787\ttest: 99.1033656\tbest: 99.0955381 (903)\ttotal: 3m 34s\tremaining: 21.7s\n",
      "908:\tlearn: 76.0002186\ttest: 99.1054678\tbest: 99.0955381 (903)\ttotal: 3m 34s\tremaining: 21.5s\n",
      "909:\tlearn: 75.9807605\ttest: 99.1111048\tbest: 99.0955381 (903)\ttotal: 3m 34s\tremaining: 21.2s\n",
      "910:\tlearn: 75.9761896\ttest: 99.1107235\tbest: 99.0955381 (903)\ttotal: 3m 34s\tremaining: 21s\n",
      "911:\tlearn: 75.9582453\ttest: 99.1093824\tbest: 99.0955381 (903)\ttotal: 3m 35s\tremaining: 20.8s\n",
      "912:\tlearn: 75.9240462\ttest: 99.1081749\tbest: 99.0955381 (903)\ttotal: 3m 35s\tremaining: 20.5s\n",
      "913:\tlearn: 75.8997735\ttest: 99.1200035\tbest: 99.0955381 (903)\ttotal: 3m 35s\tremaining: 20.3s\n",
      "914:\tlearn: 75.8813528\ttest: 99.1433632\tbest: 99.0955381 (903)\ttotal: 3m 35s\tremaining: 20s\n",
      "915:\tlearn: 75.8776018\ttest: 99.1443195\tbest: 99.0955381 (903)\ttotal: 3m 35s\tremaining: 19.8s\n",
      "916:\tlearn: 75.8634462\ttest: 99.1419611\tbest: 99.0955381 (903)\ttotal: 3m 36s\tremaining: 19.6s\n",
      "917:\tlearn: 75.8442385\ttest: 99.1477844\tbest: 99.0955381 (903)\ttotal: 3m 36s\tremaining: 19.3s\n",
      "918:\tlearn: 75.8095302\ttest: 99.1419031\tbest: 99.0955381 (903)\ttotal: 3m 36s\tremaining: 19.1s\n",
      "919:\tlearn: 75.8024099\ttest: 99.1463545\tbest: 99.0955381 (903)\ttotal: 3m 36s\tremaining: 18.8s\n",
      "920:\tlearn: 75.7996094\ttest: 99.1484280\tbest: 99.0955381 (903)\ttotal: 3m 37s\tremaining: 18.6s\n",
      "921:\tlearn: 75.7853567\ttest: 99.1474318\tbest: 99.0955381 (903)\ttotal: 3m 37s\tremaining: 18.4s\n",
      "922:\tlearn: 75.7380216\ttest: 99.1353138\tbest: 99.0955381 (903)\ttotal: 3m 37s\tremaining: 18.1s\n",
      "923:\tlearn: 75.7111279\ttest: 99.1378255\tbest: 99.0955381 (903)\ttotal: 3m 37s\tremaining: 17.9s\n",
      "924:\tlearn: 75.7028621\ttest: 99.1365677\tbest: 99.0955381 (903)\ttotal: 3m 37s\tremaining: 17.7s\n",
      "925:\tlearn: 75.6897401\ttest: 99.1363400\tbest: 99.0955381 (903)\ttotal: 3m 37s\tremaining: 17.4s\n",
      "926:\tlearn: 75.6527281\ttest: 99.1435370\tbest: 99.0955381 (903)\ttotal: 3m 38s\tremaining: 17.2s\n",
      "927:\tlearn: 75.6504501\ttest: 99.1430625\tbest: 99.0955381 (903)\ttotal: 3m 38s\tremaining: 16.9s\n",
      "928:\tlearn: 75.6259262\ttest: 99.1155840\tbest: 99.0955381 (903)\ttotal: 3m 38s\tremaining: 16.7s\n",
      "929:\tlearn: 75.6164536\ttest: 99.1151159\tbest: 99.0955381 (903)\ttotal: 3m 38s\tremaining: 16.5s\n",
      "930:\tlearn: 75.6022810\ttest: 99.1089820\tbest: 99.0955381 (903)\ttotal: 3m 39s\tremaining: 16.2s\n",
      "931:\tlearn: 75.5894747\ttest: 99.1106100\tbest: 99.0955381 (903)\ttotal: 3m 39s\tremaining: 16s\n",
      "932:\tlearn: 75.5501483\ttest: 99.0999613\tbest: 99.0955381 (903)\ttotal: 3m 39s\tremaining: 15.8s\n",
      "933:\tlearn: 75.5271022\ttest: 99.0969656\tbest: 99.0955381 (903)\ttotal: 3m 39s\tremaining: 15.5s\n",
      "934:\tlearn: 75.4821241\ttest: 99.0841898\tbest: 99.0841898 (934)\ttotal: 3m 40s\tremaining: 15.3s\n",
      "935:\tlearn: 75.4588724\ttest: 99.0815696\tbest: 99.0815696 (935)\ttotal: 3m 40s\tremaining: 15.1s\n",
      "936:\tlearn: 75.4530339\ttest: 99.0798287\tbest: 99.0798287 (936)\ttotal: 3m 40s\tremaining: 14.8s\n",
      "937:\tlearn: 75.4251791\ttest: 99.0981555\tbest: 99.0798287 (936)\ttotal: 3m 40s\tremaining: 14.6s\n",
      "938:\tlearn: 75.4036256\ttest: 99.0917751\tbest: 99.0798287 (936)\ttotal: 3m 40s\tremaining: 14.4s\n",
      "939:\tlearn: 75.4006328\ttest: 99.0938034\tbest: 99.0798287 (936)\ttotal: 3m 41s\tremaining: 14.1s\n",
      "940:\tlearn: 75.3934981\ttest: 99.0936370\tbest: 99.0798287 (936)\ttotal: 3m 41s\tremaining: 13.9s\n",
      "941:\tlearn: 75.3911759\ttest: 99.0959629\tbest: 99.0798287 (936)\ttotal: 3m 41s\tremaining: 13.6s\n",
      "942:\tlearn: 75.3731284\ttest: 99.1074519\tbest: 99.0798287 (936)\ttotal: 3m 41s\tremaining: 13.4s\n",
      "943:\tlearn: 75.3510885\ttest: 99.0944422\tbest: 99.0798287 (936)\ttotal: 3m 41s\tremaining: 13.2s\n",
      "944:\tlearn: 75.3298864\ttest: 99.0985184\tbest: 99.0798287 (936)\ttotal: 3m 42s\tremaining: 12.9s\n",
      "945:\tlearn: 75.3291190\ttest: 99.0971604\tbest: 99.0798287 (936)\ttotal: 3m 42s\tremaining: 12.7s\n",
      "946:\tlearn: 75.3167411\ttest: 99.0996752\tbest: 99.0798287 (936)\ttotal: 3m 42s\tremaining: 12.5s\n",
      "947:\tlearn: 75.2848692\ttest: 99.0654507\tbest: 99.0654507 (947)\ttotal: 3m 43s\tremaining: 12.2s\n",
      "948:\tlearn: 75.2625519\ttest: 99.0755180\tbest: 99.0654507 (947)\ttotal: 3m 43s\tremaining: 12s\n",
      "949:\tlearn: 75.2458872\ttest: 99.0784126\tbest: 99.0654507 (947)\ttotal: 3m 43s\tremaining: 11.8s\n",
      "950:\tlearn: 75.2189736\ttest: 99.0674712\tbest: 99.0654507 (947)\ttotal: 3m 43s\tremaining: 11.5s\n",
      "951:\tlearn: 75.1959510\ttest: 99.0562921\tbest: 99.0562921 (951)\ttotal: 3m 43s\tremaining: 11.3s\n",
      "952:\tlearn: 75.1866691\ttest: 99.0586581\tbest: 99.0562921 (951)\ttotal: 3m 44s\tremaining: 11.1s\n",
      "953:\tlearn: 75.1636297\ttest: 99.0699477\tbest: 99.0562921 (951)\ttotal: 3m 44s\tremaining: 10.8s\n",
      "954:\tlearn: 75.1389885\ttest: 99.0725562\tbest: 99.0562921 (951)\ttotal: 3m 44s\tremaining: 10.6s\n",
      "955:\tlearn: 75.1163403\ttest: 99.0803560\tbest: 99.0562921 (951)\ttotal: 3m 44s\tremaining: 10.3s\n",
      "956:\tlearn: 75.0797815\ttest: 99.0999108\tbest: 99.0562921 (951)\ttotal: 3m 45s\tremaining: 10.1s\n",
      "957:\tlearn: 75.0450260\ttest: 99.0863191\tbest: 99.0562921 (951)\ttotal: 3m 45s\tremaining: 9.87s\n",
      "958:\tlearn: 75.0357882\ttest: 99.0869043\tbest: 99.0562921 (951)\ttotal: 3m 45s\tremaining: 9.64s\n",
      "959:\tlearn: 75.0262202\ttest: 99.0889946\tbest: 99.0562921 (951)\ttotal: 3m 45s\tremaining: 9.4s\n",
      "960:\tlearn: 75.0099456\ttest: 99.0905459\tbest: 99.0562921 (951)\ttotal: 3m 45s\tremaining: 9.17s\n",
      "961:\tlearn: 74.9660265\ttest: 99.0810967\tbest: 99.0562921 (951)\ttotal: 3m 46s\tremaining: 8.93s\n",
      "962:\tlearn: 74.9287246\ttest: 99.0789060\tbest: 99.0562921 (951)\ttotal: 3m 46s\tremaining: 8.7s\n",
      "963:\tlearn: 74.9146594\ttest: 99.0832853\tbest: 99.0562921 (951)\ttotal: 3m 46s\tremaining: 8.46s\n",
      "964:\tlearn: 74.8880288\ttest: 99.0638534\tbest: 99.0562921 (951)\ttotal: 3m 46s\tremaining: 8.23s\n",
      "965:\tlearn: 74.8769292\ttest: 99.0622424\tbest: 99.0562921 (951)\ttotal: 3m 47s\tremaining: 8s\n",
      "966:\tlearn: 74.8199441\ttest: 99.0423351\tbest: 99.0423351 (966)\ttotal: 3m 47s\tremaining: 7.76s\n",
      "967:\tlearn: 74.8147648\ttest: 99.0448883\tbest: 99.0423351 (966)\ttotal: 3m 47s\tremaining: 7.53s\n",
      "968:\tlearn: 74.8035868\ttest: 99.0488453\tbest: 99.0423351 (966)\ttotal: 3m 47s\tremaining: 7.29s\n",
      "969:\tlearn: 74.7883122\ttest: 99.0482441\tbest: 99.0423351 (966)\ttotal: 3m 48s\tremaining: 7.06s\n",
      "970:\tlearn: 74.7695674\ttest: 99.0332771\tbest: 99.0332771 (970)\ttotal: 3m 48s\tremaining: 6.82s\n",
      "971:\tlearn: 74.7582004\ttest: 99.0360359\tbest: 99.0332771 (970)\ttotal: 3m 48s\tremaining: 6.58s\n",
      "972:\tlearn: 74.7534602\ttest: 99.0368535\tbest: 99.0332771 (970)\ttotal: 3m 48s\tremaining: 6.35s\n",
      "973:\tlearn: 74.7308955\ttest: 99.0405784\tbest: 99.0332771 (970)\ttotal: 3m 49s\tremaining: 6.11s\n",
      "974:\tlearn: 74.7159776\ttest: 99.0349281\tbest: 99.0332771 (970)\ttotal: 3m 49s\tremaining: 5.88s\n",
      "975:\tlearn: 74.6855119\ttest: 99.0416337\tbest: 99.0332771 (970)\ttotal: 3m 49s\tremaining: 5.64s\n",
      "976:\tlearn: 74.6665139\ttest: 99.0361228\tbest: 99.0332771 (970)\ttotal: 3m 49s\tremaining: 5.41s\n",
      "977:\tlearn: 74.6437384\ttest: 99.0430466\tbest: 99.0332771 (970)\ttotal: 3m 49s\tremaining: 5.17s\n",
      "978:\tlearn: 74.6300833\ttest: 99.0375053\tbest: 99.0332771 (970)\ttotal: 3m 50s\tremaining: 4.94s\n",
      "979:\tlearn: 74.6128875\ttest: 99.0459311\tbest: 99.0332771 (970)\ttotal: 3m 50s\tremaining: 4.7s\n",
      "980:\tlearn: 74.5836753\ttest: 99.0422326\tbest: 99.0332771 (970)\ttotal: 3m 50s\tremaining: 4.46s\n",
      "981:\tlearn: 74.5584302\ttest: 99.0420956\tbest: 99.0332771 (970)\ttotal: 3m 50s\tremaining: 4.23s\n",
      "982:\tlearn: 74.5469059\ttest: 99.0397069\tbest: 99.0332771 (970)\ttotal: 3m 50s\tremaining: 3.99s\n",
      "983:\tlearn: 74.5285685\ttest: 99.0411289\tbest: 99.0332771 (970)\ttotal: 3m 51s\tremaining: 3.76s\n",
      "984:\tlearn: 74.5112136\ttest: 99.0266640\tbest: 99.0266640 (984)\ttotal: 3m 51s\tremaining: 3.52s\n",
      "985:\tlearn: 74.4848365\ttest: 99.0302883\tbest: 99.0266640 (984)\ttotal: 3m 51s\tremaining: 3.29s\n",
      "986:\tlearn: 74.4814177\ttest: 99.0292146\tbest: 99.0266640 (984)\ttotal: 3m 51s\tremaining: 3.06s\n",
      "987:\tlearn: 74.4514032\ttest: 99.0367842\tbest: 99.0266640 (984)\ttotal: 3m 52s\tremaining: 2.82s\n",
      "988:\tlearn: 74.4143122\ttest: 99.0262883\tbest: 99.0262883 (988)\ttotal: 3m 52s\tremaining: 2.58s\n",
      "989:\tlearn: 74.3950266\ttest: 99.0412042\tbest: 99.0262883 (988)\ttotal: 3m 52s\tremaining: 2.35s\n",
      "990:\tlearn: 74.3764343\ttest: 99.0296967\tbest: 99.0262883 (988)\ttotal: 3m 52s\tremaining: 2.12s\n",
      "991:\tlearn: 74.3323195\ttest: 99.0321491\tbest: 99.0262883 (988)\ttotal: 3m 53s\tremaining: 1.88s\n",
      "992:\tlearn: 74.3142440\ttest: 99.0270849\tbest: 99.0262883 (988)\ttotal: 3m 53s\tremaining: 1.65s\n",
      "993:\tlearn: 74.3057513\ttest: 99.0252579\tbest: 99.0252579 (993)\ttotal: 3m 53s\tremaining: 1.41s\n",
      "994:\tlearn: 74.2677590\ttest: 99.0168305\tbest: 99.0168305 (994)\ttotal: 3m 53s\tremaining: 1.18s\n",
      "995:\tlearn: 74.2473575\ttest: 99.0242461\tbest: 99.0168305 (994)\ttotal: 3m 54s\tremaining: 940ms\n",
      "996:\tlearn: 74.2242078\ttest: 99.0103186\tbest: 99.0103186 (996)\ttotal: 3m 54s\tremaining: 705ms\n",
      "997:\tlearn: 74.2035208\ttest: 99.0067516\tbest: 99.0067516 (997)\ttotal: 3m 54s\tremaining: 470ms\n",
      "998:\tlearn: 74.1864495\ttest: 99.0056058\tbest: 99.0056058 (998)\ttotal: 3m 54s\tremaining: 235ms\n",
      "999:\tlearn: 74.1805154\ttest: 99.0034888\tbest: 99.0034888 (999)\ttotal: 3m 55s\tremaining: 0us\n",
      "\n",
      "bestTest = 99.00348875\n",
      "bestIteration = 999\n",
      "\n",
      "5610.250886021344\n",
      "9801.690785409855\n",
      "rooms: 15.313121181374267\n",
      "accommodates: 7.279334311532233\n",
      "major_city: 6.384230435604344\n",
      "room_type: 6.118507791338721\n",
      "bathrooms: 5.9584259752400985\n",
      "bedrooms: 3.311216734662245\n",
      "host_response_rate: 2.8417580378766423\n",
      "zipcode: 2.6198610724279554\n",
      "city: 2.398323001748451\n",
      "number_of_reviews: 2.325652816062186\n",
      "first_review: 2.2262929518149863\n",
      "median_home_value: 1.7116309946844581\n",
      "review_scores_rating: 1.4963262994089785\n",
      "latitude: 1.4776726062495116\n",
      "last_review: 1.4517797649429434\n",
      "desc_48: 1.3772727282995967\n",
      "last_review_month: 1.334849522575384\n",
      "desc_37: 1.3344594008888884\n",
      "median_household_income: 1.1797989941844356\n",
      "first_review_month: 1.0391906327930218\n",
      "land_area_in_sqmi: 1.0291723818956677\n",
      "longitude: 1.0251392306119451\n",
      "neighbourhood: 0.9509740576268632\n",
      "property_type: 0.9094446669340859\n",
      "desc_2: 0.8679776146615079\n",
      "desc_40: 0.7542677116082654\n",
      "dis_0: 0.7362742549010202\n",
      "desc_32: 0.6882261657983416\n",
      "desc_39: 0.6686393459621062\n",
      "beds: 0.6561601849496526\n",
      "desc_28: 0.6298964302102246\n",
      "occupied_housing_rate: 0.626606355148051\n",
      "desc_35: 0.6183463592815307\n",
      "desc_42: 0.5776925886953048\n",
      "host_since: 0.5767027062995003\n",
      "desc_24: 0.5598416069294396\n",
      "cleaning_fee: 0.5515389585318116\n",
      "desc_44: 0.5474679459406616\n",
      "desc_0: 0.5063801572962427\n",
      "Pool: 0.497174932489008\n",
      "Suitable for events: 0.4851903514338016\n",
      "desc_22: 0.46978694702685775\n",
      "word_num: 0.44378254228387826\n",
      "desc_5: 0.4263346194215848\n",
      "am_num: 0.4124881225786358\n",
      "desc_3: 0.3983605985083051\n",
      "desc_31: 0.3925668928209229\n",
      "desc_8: 0.3818093467323853\n",
      "host_since_month: 0.37943693134777773\n",
      "desc_15: 0.3749304954154197\n",
      "desc_34: 0.37449737829625485\n",
      "desc_47: 0.35189544304563897\n",
      "desc_21: 0.3450899703963958\n",
      "population_density: 0.3362359126150469\n",
      "desc_46: 0.3247702051141246\n",
      "desc_41: 0.31356174196660797\n",
      "desc_27: 0.31068611565342863\n",
      "desc_20: 0.30965998634109293\n",
      "desc_33: 0.2978315397331171\n",
      "desc_45: 0.29604167249512875\n",
      "desc_7: 0.2918676260098447\n",
      "desc_30: 0.291258975760163\n",
      "desc_14: 0.2868360291679807\n",
      "Elevator: 0.282182186657942\n",
      "desc_26: 0.28119629192015555\n",
      "desc_9: 0.2761276836717137\n",
      "Cable TV: 0.27547423141980143\n",
      "TV: 0.2726435040812807\n",
      "population: 0.24528212564336038\n",
      "cancellation_policy: 0.237028833793343\n",
      "Buzzer/wireless intercom: 0.23622981325767622\n",
      "housing_units: 0.22993946218120187\n",
      "desc_18: 0.22912776076641592\n",
      "desc_17: 0.2174370146986339\n",
      "desc_11: 0.2164987738742725\n",
      "water_area_in_sqmi: 0.21593457441739639\n",
      "Breakfast: 0.21369302274828966\n",
      "desc_16: 0.20923336217897995\n",
      "desc_12: 0.20821412788939406\n",
      "Essentials: 0.20757530536338312\n",
      "desc_19: 0.20751761499913005\n",
      "Indoor fireplace: 0.2049267088561508\n",
      "desc_23: 0.20360773188163528\n",
      "desc_1: 0.2025645255279713\n",
      "desc_25: 0.1887504672261635\n",
      "desc_13: 0.18338881473518828\n",
      "desc_38: 0.18022787358949466\n",
      "desc_29: 0.17700849008702219\n",
      "desc_6: 0.17617593664394432\n",
      "occupied_housing_units: 0.16979499827583439\n",
      "desc_49: 0.16934756193213826\n",
      "desc_36: 0.1560443992925967\n",
      "Gym: 0.15497846412880856\n",
      "desc_4: 0.13757675858495289\n",
      "desc_43: 0.13050338378785328\n",
      "Hot tub: 0.11549006158497264\n",
      "desc_10: 0.10358466049461501\n",
      "Smoke detector: 0.09666978300344384\n",
      "Elevator in building: 0.08798806129786048\n",
      "Private entrance: 0.08773599946370937\n",
      "Lock on bedroom door: 0.08110013825899588\n",
      "host_identity_verified: 0.07817504766652578\n",
      "Doorman: 0.07809519764344652\n",
      "dis_1: 0.0702274386057801\n",
      "Family/kid friendly: 0.059025759058495796\n",
      "Fire extinguisher: 0.05796910585672033\n",
      "Self Check-In: 0.05568982338892028\n",
      "Hair dryer: 0.054943165561773755\n",
      "Hangers: 0.05357069726497722\n",
      "Iron: 0.051049936314494115\n",
      "Free parking on premises: 0.050207952650247925\n",
      "Pets allowed: 0.049519888911620534\n",
      "First aid kit: 0.047546854803370314\n",
      "translation missing: en.hosting_amenity_50: 0.04175242906911517\n",
      "host_has_profile_pic: 0.03903121897518849\n",
      "Wheelchair accessible: 0.03499102746185273\n",
      "Air conditioning: 0.0328259528643428\n",
      "Laptop friendly workspace: 0.03177003460379407\n",
      "Dryer: 0.031589094324815555\n",
      "Kitchen: 0.03155909159464332\n",
      "bed_type: 0.029630045767627178\n",
      "Heating: 0.02934264975936234\n",
      "Internet: 0.02723447223726644\n",
      "Washer: 0.025734165174154115\n",
      "Carbon monoxide detector: 0.02439844200845009\n",
      "Bathtub: 0.02430966608834202\n",
      "Smoking allowed: 0.023522497820624738\n",
      "24-hour check-in: 0.02088605847784752\n",
      "Wireless Internet: 0.01645930951526767\n",
      "instant_bookable: 0.016325808186918898\n",
      "Shampoo: 0.015709453188920964\n",
      "translation missing: en.hosting_amenity_49: 0.014466771987755273\n",
      "Children’s books and toys: 0.012529196848618064\n",
      "Dishwasher: 0.010859808257415424\n",
      "Pets live on this property: 0.01036333490092095\n",
      "Cat(s): 0.009808382015658047\n",
      "Lockbox: 0.005554669376362939\n",
      "Dog(s): 0.0050645355664042276\n",
      "Microwave: 0.004852682456437244\n",
      "Pack ’n Play/travel crib: 0.0011001058098103118\n",
      "Private living room: 0.0009593660749890746\n",
      "host_since_hot: 0.0\n",
      "Well-lit path to entrance: 0.0\n",
      "Stove: 0.0\n",
      "Step-free access: 0.0\n",
      "Smartlock: 0.0\n",
      "Safety card: 0.0\n",
      "Room-darkening shades: 0.0\n",
      "Refrigerator: 0.0\n",
      "Patio or balcony: 0.0\n",
      "Oven: 0.0\n",
      "Luggage dropoff allowed: 0.0\n",
      "Long term stays allowed: 0.0\n",
      "Keypad: 0.0\n",
      "Hot water: 0.0\n",
      "Host greets you: 0.0\n",
      "Garden or backyard: 0.0\n",
      "Extra pillows and blankets: 0.0\n",
      "Dishes and silverware: 0.0\n",
      "Cooking basics: 0.0\n",
      "Coffee maker: 0.0\n",
      "Bed linens: 0.0\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "import catboost\n",
    "from catboost import Pool\n",
    "import sklearn.preprocessing as sp\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def CAT(train_X_df,train_Y_df,test_X_df,test_size=0):\n",
    "    # 代入されないようシャドーコピー\n",
    "    train_X,train_Y,test_X = copy(train_X_df),copy(train_Y_df),copy(test_X_df)\n",
    "    # データ分割(test_sizeを指定しない場合は分割しない)\n",
    "    if test_size:\n",
    "        train_X, train_X_split, train_Y, train_Y_split = train_test_split(train_X, train_Y, test_size=test_size)\n",
    "    # データを変換\n",
    "    cat_features = train_X.dtypes[train_X.dtypes == 'category'].index\n",
    "    c_train = Pool(train_X, label=train_Y,cat_features=cat_features)\n",
    "    if test_size: c_train_split = Pool(train_X_split, label=train_Y_split,cat_features=cat_features)\n",
    "    c_test = Pool(test_X,cat_features=cat_features)\n",
    "    # モデル定義\n",
    "    model = catboost.CatBoostRegressor(iterations=100000, loss_function='RMSE')\n",
    "    # 学習\n",
    "    if test_size:\n",
    "        model.fit(c_train, eval_set=c_train_split,early_stopping_rounds=1000, use_best_model=True,verbose=True)\n",
    "    else:\n",
    "        model.fit(c_train, early_stopping_rounds=1000, use_best_model=True,verbose=True)\n",
    "\n",
    "    # モデルの評価(データ分割をしている場合としてしない場合で分岐)\n",
    "    \n",
    "    if test_size:\n",
    "        pred_train = model.predict(c_train)\n",
    "        pred_test = model.predict(c_train_split)\n",
    "        print(mean_squared_error(train_Y, pred_train))\n",
    "        print(mean_squared_error(train_Y_split, pred_test))\n",
    "    else:\n",
    "        pred_train = model.predict(c_train)\n",
    "        print(mean_squared_error(train_Y, pred_train))\n",
    "\n",
    "    # モデルの予測\n",
    "    predictions = model.predict(c_test)\n",
    "\n",
    "    return predictions, model.get_feature_importance(c_train), train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 100 # モデルの数\n",
    "timeout = 100000 # 何秒経ったら切り上げるか\n",
    "\n",
    "dir_path = '/submit/subs'\n",
    "\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "for i in range(model_num):\n",
    "    predictions, feature_importances, feature_names = CAT(train_X_df,train['y'],test_X_df,test_size=0.1)\n",
    "    results = predictions.flatten()\n",
    "    pd.DataFrame(results).to_csv(os.path.join(dir_path, str(i+1) + 'sub.csv'), header=False, index=True)\n",
    "    if (time.perf_counter() - start) > timeout: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n",
    "    print('{}: {}'.format(name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "csvs = glob(dir_path + '*')\n",
    "csv_list = [pd.read_csv(csv, header=None) for csv in csvs]\n",
    "sum_csv = sum(csv_list) / len(csv_list)\n",
    "\n",
    "pd.DataFrame(sum_csv).to_csv('submit.csv', header=False, index=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "str.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python385jvsc74a57bd031a0bd1b30e8c04f37bec027b053c811f2843e91793e64a65057c2e9d4698735",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}