{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"orig_nbformat":2,"kernelspec":{"name":"python385jvsc74a57bd031a0bd1b30e8c04f37bec027b053c811f2843e91793e64a65057c2e9d4698735","display_name":"Python 3.8.5 64-bit ('base': conda)"},"colab":{"name":"str.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TcrFhXk0GYV7","executionInfo":{"status":"ok","timestamp":1620291128814,"user_tz":-540,"elapsed":946,"user":{"displayName":"工藤奎太朗","photoUrl":"","userId":"17571128482548330974"}}},"source":["import os\n","import re\n","import pandas as pd\n","import numpy as np\n","\n","train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 最終的に学習・予測に使うDataFrame\n","train_X_df = pd.DataFrame()\n","test_X_df = pd.DataFrame()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# strで書かれてしまったリストをndarrayに変換する\n","def str_to_nd(strs):\n","    strs = re.sub('[{}\"]','',strs)\n","    str_list = strs.split(',')\n","    str_nd = np.array(str_list)\n","    return str_nd\n","\n","# リストをOne-Hotに変換する\n","from sklearn.preprocessing import MultiLabelBinarizer\n","def list_to_onehot(train,test):\n","    mlb = MultiLabelBinarizer()\n","    train_onehot = mlb.fit_transform(train.values)\n","    test_onehot = mlb.transform(test.values)\n","    train_onehot_df = pd.DataFrame(train_onehot, columns = mlb.classes_)\n","    columns_list = train_onehot_df.mean()[train_onehot_df.mean()>0.01].index.tolist()\n","    train_onehot_df = train_onehot_df[columns_list]\n","    test_onehot_df = pd.DataFrame(test_onehot, columns = mlb.classes_)\n","    test_onehot_df = test_onehot_df[columns_list]\n","    return train_onehot_df.astype('int').astype('category'),test_onehot_df.astype('int').astype('category')\n","\n","# アメニティデータ\n","train['amenities'] = train['amenities'].map(str_to_nd)\n","test['amenities'] = test['amenities'].map(str_to_nd)\n","train_X_df = pd.concat([train_X_df,list_to_onehot(train['amenities'],test['amenities'])[0]], axis=1)\n","test_X_df = pd.concat([test_X_df,list_to_onehot(train['amenities'],test['amenities'])[1]], axis=1)\n","# アメニティの数\n","train_X_df = pd.concat([train_X_df,train['amenities'].map(lambda x:len(x)).rename('am_num')], axis=1)\n","test_X_df = pd.concat([test_X_df,test['amenities'].map(lambda x:len(x)).rename('am_num')], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# カテゴリー系のデータをラベルにする\n","import itertools\n","import category_encoders as ce\n","def df_to_label(train,test):\n","    train,test = train.fillna('nan'),test.fillna('nan')\n","    oe = ce.OrdinalEncoder(handle_unknown='return nan')\n","    train_oe = oe.fit_transform(train).fillna(0).astype(int).astype('category')\n","    test_oe = oe.transform(test).fillna(0).astype(int).astype('category')\n","    return train_oe,test_oe\n","\n","# カテゴリー系データ\n","cat_list = ['bed_type','cancellation_policy','city','cleaning_fee','host_has_profile_pic','host_identity_verified','instant_bookable','property_type','room_type']\n","train_X_df = pd.concat([train_X_df,df_to_label(train[cat_list],test[cat_list])[0]], axis=1)\n","test_X_df = pd.concat([test_X_df,df_to_label(train[cat_list],test[cat_list])[1]], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 日付関連のデータを整形\n","def str_to_date_zero(df):\n","    # year型(年情報)に変換、欠損値はそのまま\n","    df_date = df.applymap(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').year if x==x else x)\n","\n","    # (データの中で一番最新の日付)-(データの日付)にすることで、「反応してからn年経っている」という情報に置き換える\n","    latest_year = df_date.max().max()\n","    df_date = df_date.applymap(lambda x: latest_year - x)\n","\n","    # 欠損値は一番遅かった日付のデータに合わせる\n","    #df_date = df_date.fillna(0)\n","\n","    return df_date\n","\n","# 日付関連のデータ\n","date_list = ['host_since','first_review','last_review']\n","train_X_df = pd.concat([train_X_df,str_to_date_zero(train[date_list])], axis=1)\n","test_X_df = pd.concat([test_X_df,str_to_date_zero(test[date_list])], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 月のデータ\n","str_to_month = lambda x: datetime.datetime.strptime(x,'%Y-%m-%d').month if x==x else x\n","train_X_df = pd.concat([train_X_df,train['host_since'].map(str_to_month).rename('host_since_month')], axis=1)\n","test_X_df = pd.concat([test_X_df,test['host_since'].map(str_to_month).rename('host_since_month')], axis=1)\n","\n","train_X_df = pd.concat([train_X_df,train['first_review'].map(str_to_month).rename('first_review_month')], axis=1)\n","test_X_df = pd.concat([test_X_df,test['first_review'].map(str_to_month).rename('first_review_month')], axis=1)\n","\n","train_X_df = pd.concat([train_X_df,train['last_review'].map(str_to_month).rename('last_review_month')], axis=1)\n","test_X_df = pd.concat([test_X_df,test['last_review'].map(str_to_month).rename('last_review_month')], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 反応があるかないかをOne-Hotデータで表現する\n","def res_to_onehot(df):\n","    df = df.applymap(lambda x: 1 if x==x else 0)\n","    df = df.set_axis([x+'_hot' for x in df.columns], axis=1)\n","    return df.astype('category')\n","\n","res_list = ['host_since']\n","train_X_df = pd.concat([train_X_df,res_to_onehot(train[res_list])], axis=1)\n","test_X_df = pd.concat([test_X_df,res_to_onehot(test[res_list])], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# str型のパーセンテージで書かれたデータを0~1のfloat型にする\n","def strper_to_float(strper):\n","    if strper==strper:\n","        strnum = re.sub('%','',strper)\n","        num_float = float(strnum) / 100.\n","    else:\n","        num_float = np.nan\n","    return num_float\n","\n","# str型のパーセンテージ\n","train['host_response_rate'] = train['host_response_rate'].map(strper_to_float)\n","test['host_response_rate'] = test['host_response_rate'].map(strper_to_float)\n","\n","# float型データ\n","num_list = ['accommodates','bathrooms','bedrooms','beds','latitude','longitude','number_of_reviews','review_scores_rating','host_response_rate']\n","train_X_df = pd.concat([train_X_df,train[num_list]], axis=1)\n","test_X_df = pd.concat([test_X_df,test[num_list]], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 緯度経度から地理情報を入手\n","from uszipcode import SearchEngine\n","search = SearchEngine()\n","def latlon_to_geo(lat, lon):\n","    d = search.by_coordinates(lat, lon, radius=20)[0].to_dict()\n","    return pd.DataFrame([d])\n","\n","def data_to_geo(df):\n","    geo = pd.concat([latlon_to_geo(x,y) for x,y in zip(df['latitude'],df['longitude'])])\n","    return geo\n","\n","def geo_cat_num(geo):\n","    geo['zipcode'] = geo['zipcode'].apply(lambda x:str(x)[:5])\n","    cat_list = ['zipcode', \n","                'major_city']\n","\n","    num_list = ['population', \n","                'population_density', \n","                'land_area_in_sqmi', \n","                'water_area_in_sqmi', \n","                'housing_units', \n","                'occupied_housing_units', \n","                'median_home_value', \n","                'median_household_income']\n","    \n","    return geo[cat_list], geo[num_list]\n","\n","# DataFrameの作成が非常に遅いため、DataFrameを作成したらcsvとして保存し次に使うときはcsvから読み込む\n","\n","if os.path.isfile('train_geo.csv'):\n","    train_geo = pd.read_csv('train_geo.csv', index_col=0)\n","else:\n","    train_geo = data_to_geo(train).reset_index()\n","    train_geo.to_csv('train_geo.csv', header=True, index=True)\n","train_geo_cat, train_geo_num = geo_cat_num(train_geo)\n","\n","if os.path.isfile('test_geo.csv'):\n","    test_geo = pd.read_csv('test_geo.csv', index_col=0)\n","else:\n","    test_geo = data_to_geo(test).reset_index()\n","    test_geo.to_csv('test_geo.csv', header=True, index=True)\n","test_geo_cat, test_geo_num = geo_cat_num(test_geo)\n","\n","train_X_df = pd.concat([train_X_df,df_to_label(train_geo_cat,test_geo_cat)[0]], axis=1)\n","test_X_df = pd.concat([test_X_df,df_to_label(train_geo_cat,test_geo_cat)[1]], axis=1)\n","train_X_df = pd.concat([train_X_df,train_geo_num], axis=1)\n","test_X_df = pd.concat([test_X_df,test_geo_num], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# descriptionの単語数を調べる\n","from collections import Counter\n","wordnum = lambda x:sum(Counter(x.split()).values())\n","train_X_df = pd.concat([train_X_df,train['description'].map(wordnum).rename('word_num')], axis=1)\n","test_X_df = pd.concat([test_X_df,test['description'].map(wordnum).rename('word_num')], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 部屋数\n","train_X_df['rooms'] = train_X_df['bedrooms'] + train_X_df['bathrooms']\n","test_X_df['rooms'] = test_X_df['bedrooms'] + test_X_df['bathrooms']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 価格が高い地点との距離を測る\n","top_loc = np.array([[-118.813009,34.028313],[-118.448221,34.132164]])\n","\n","def u_dis(x1,y1,x2,y2):\n","    return np.sqrt((x1-x2)**2 + (y1-y2)**2)\n","\n","def min_dis(df):\n","    tmp = np.empty(2)\n","    for i,x,y in zip(range(1),top_loc[:,0],top_loc[:,1]):\n","        tmp[i] = u_dis(df['longitude'],df['latitude'],x,y)\n","    return tmp\n","\n","train_X_df = pd.concat([train_X_df,train_X_df.apply(min_dis, axis=1).apply(pd.Series)], axis=1)\n","test_X_df = pd.concat([test_X_df,test_X_df.apply(min_dis, axis=1).apply(pd.Series)], axis=1)\n","\n","train_X_df = train_X_df.rename(columns=dict([(x,'dis_'+str(x)) for x in range(10)]))\n","test_X_df = test_X_df.rename(columns=dict([(x,'dis_'+str(x)) for x in range(10)]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 占有住宅率\n","train_X_df['occupied_housing_rate'] = train_X_df['occupied_housing_units'] / train_X_df['housing_units']\n","test_X_df['occupied_housing_rate'] = test_X_df['occupied_housing_units'] / test_X_df['housing_units']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from copy import copy\n","from sklearn.model_selection import train_test_split\n","# トレーニングデータとテストデータを分割\n","train_X,train_Y,test_X = copy(train_X_df),copy(train['y']),copy(test_X_df)\n","train_X, train_X_split, train_Y, train_Y_split = train_test_split(train_X, train_Y, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math\n","from sklearn.metrics import mean_squared_error\n","from catboost import Pool\n","import catboost\n","import sklearn.metrics\n","import sklearn.preprocessing as sp\n","def objective(trial):\n","    # データを変換\n","    cat_features = train_X.dtypes[train_X.dtypes == 'category'].index\n","    c_train = Pool(train_X, label=train_Y,cat_features=cat_features)\n","    c_train_split = Pool(train_X_split, label=train_Y_split,cat_features=cat_features)\n","    c_test = Pool(test_X,cat_features=cat_features)\n","\n","    # パラメータの指定\n","    params = {\n","        'iterations' : trial.suggest_int('iterations', 50, 300),                         \n","        'depth' : trial.suggest_int('depth', 4, 10),                                       \n","        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.3),               \n","        'random_strength' :trial.suggest_int('random_strength', 0, 100),                       \n","        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00), \n","        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n","        'od_wait' :trial.suggest_int('od_wait', 10, 50)\n","    }\n","\n","    # 学習の平均値をとる\n","    pre_list = np.empty((20,test.shape[0]))\n","    model = catboost.CatBoostRegressor(**params, loss_function='RMSE',task_type='GPU', max_bin=250)\n","    for i in range(20):\n","        model.fit(c_train, eval_set=c_train_split, early_stopping_rounds=10,verbose=False)\n","        pre_list[i] = math.sqrt(mean_squared_error(train_Y_split, model.predict(c_train_split)))\n","\n","    return np.mean(pre_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["import optuna\n","# 最適パラメータ取得\n","study = optuna.create_study()\n","study.optimize(objective, timeout=3600)\n","trial = study.best_trial\n","params_best = dict(trial.params.items())\n","params_best['random_seed'] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cat_features = train_X.dtypes[train_X.dtypes == 'category'].index\n","c_train = Pool(train_X, label=train_Y,cat_features=cat_features)\n","c_train_split = Pool(train_X_split, label=train_Y_split,cat_features=cat_features)\n","c_test = Pool(test_X,cat_features=cat_features)\n","\n","pre_list = np.empty((20,test.shape[0]))\n","model_o = catboost.CatBoostRegressor(**params_best, loss_function='RMSE',task_type='GPU', max_bin=250)\n","for i in range(20):\n","    model_o.fit(c_train, eval_set=c_train_split, early_stopping_rounds=10,verbose=False)\n","    pre_list[i] = model_o.predict(c_test).flatten()\n","results = np.mean(pre_list, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame(results).to_csv('submit/submit.csv', header=False, index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !pip install lightgbm\n","# !pip install optuna"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#!pip install category_encoders"]}]}